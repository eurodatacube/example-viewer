<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Monitoring socio-economic activities with nighttime light maps - EarthCODE Examples</title><meta property="og:title" content="Monitoring socio-economic activities with nighttime light maps - EarthCODE Examples"/><meta name="generator" content="mystmd"/><meta name="description" content="Collection of examples relevant to the EarthCODE project"/><meta property="og:description" content="Collection of examples relevant to the EarthCODE project"/><meta name="keywords" content=""/><meta name="image" content="/example-viewer/build/fb2486d4e1708daa94616c6ae8fc4cc9.jpeg"/><meta property="og:image" content="/example-viewer/build/fb2486d4e1708daa94616c6ae8fc4cc9.jpeg"/><link rel="stylesheet" href="/example-viewer/build/_assets/app-HG4THSM4.css"/><link rel="stylesheet" href="/example-viewer/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/example-viewer/favicon.ico"/><link rel="stylesheet" href="/example-viewer/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/example-viewer/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3iop:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-none pr-2 smallcaps">EarthCODE Examples</div><div class="flex-grow"></div><a href="https://github.com/esa-earthcode/example-viewer/" title="GitHub Repository: esa-earthcode/example-viewer/" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="inline-block mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block"><title>Jupyter Notebook</title><path d="M20.2 1.7c0 .8-.5 1.4-1.3 1.5-.8 0-1.4-.5-1.5-1.3 0-.8.5-1.4 1.3-1.5.8-.1 1.5.5 1.5 1.3zM12 17.9c-3.7 0-7-1.3-8.7-3.3 1.8 4.8 7.1 7.3 11.9 5.5 2.5-.9 4.5-2.9 5.5-5.5-1.7 2-4.9 3.3-8.7 3.3zM12 5.1c3.7 0 7 1.3 8.7 3.3-1.8-4.8-7.1-7.3-11.9-5.5-2.5.9-4.5 2.9-5.5 5.5 1.7-2 5-3.3 8.7-3.3zM6.9 21.8c.1 1-.7 1.8-1.7 1.9-1 .1-1.8-.7-1.9-1.7 0-1 .7-1.8 1.7-1.9 1-.1 1.8.7 1.9 1.7zM3.7 4.6c-.6 0-1-.4-1-1s.4-1 1-1 1 .4 1 1c0 .5-.4 1-1 1z"></path></svg></div><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rd4fop:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Monitoring socio-economic activities with nighttime light maps</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="jTGnI5dJyT" class="relative group/block"><h1 id="monitoring-socio-economic-activities-with-nighttime-light-maps" class="relative group"><span class="heading-text">Monitoring socio-economic activities with nighttime light maps</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#monitoring-socio-economic-activities-with-nighttime-light-maps" title="Link to this Section" aria-label="Link to this Section">¶</a></h1><h2 id="case-study-creating-nighttime-light-maps-with-color-blending" class="relative group"><span class="heading-text">Case study: Creating nighttime light maps with color blending</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#case-study-creating-nighttime-light-maps-with-color-blending" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="hZNBR93C9U" class="relative group/block"><p>This notebook demonstrates how to create nighttime light variation maps over a time interval (from 2019 to 2022) with additive color blending for studying the distribution of artificial lighting in urban and rural regions, offering insights into urbanization, infrastructure development, and socio-economic activity.
The Nighttime Light Levels indicator can be explored on the EO Dashboard by selecting the EXPLORE DATASETS mode and choosing <a target="_blank" rel="noreferrer" href="https://eodashboard.org/explore?indicator=NTLU&amp;x=12142837.23019&amp;y=4137471.98879&amp;z=5.69238" class="">Night lights indicators</a>.</p><p>The study has been carried out by <strong>Bumpei Tojo PhD (Associate Professor), School of International and Area Studies, Tokyo University of Foreign Studies, Japan</strong>.</p><p>The <strong>PLES Engineering team</strong> (supporting <em>ESA Green Solutions Division</em>, EOP-SG) developed the blending algorithm with the current Notebook implementation and data ingestion on the dashboard (contacts: <strong>Federico Rondoni</strong>, <a target="_blank" rel="noreferrer" href="mailto:f.rondoni@stariongroup.eu" class="">f<wbr/>.rondoni@stariongroup<wbr/>.eu</a>, <strong>Diego Moglioni</strong>, <a target="_blank" rel="noreferrer" href="mailto:d.moglioni@stariongroup.eu" class="">d<wbr/>.moglioni@stariongroup<wbr/>.eu</a>).</p></div><div id="ZMstn06VYS" class="relative group/block"><p><img id="EdayEuiaMv" style="margin:0 auto" src="/example-viewer/build/fb2486d4e1708daa94616c6ae8fc4cc9.jpeg" alt="title" data-canonical-url="data:image/jpeg;base64,/9j/4AAQSk...YkVWooA//Z"/>
Example of a nighttime light map covering Northeastern United States during 2019-2022, representing areas where a decrease in nighttime light level occurred (indicating a presumed reduction in social activity) in red, and areas where an increase occurred (indicating a presumed increase in social activity) in blue.</p></div><div id="Mix4ftCiFF" class="relative group/block"><h2 id="input-data" class="relative group"><span class="heading-text">Input data:</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#input-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><ul><li>This product was developed by JAXA by aggregating the data from the Visible Infrared Imaging Radiometer Suite (VIIRS, onboard the Suomi NPP satellite) on a semi-annual basis (using median image generation) with 10-degree lat/lon (geographic) grid h-v tile as Geo Tiff files.</li><li>The tiles are 2400 x 2400 pixels, with pixel size of 0.004166 degrees (~464 m at the equator).</li><li>Metric: nighttime radiance (measured in watts per square centimeter per steradian, [W/cm²/sr]), which represents the brightness of artificial lighting.</li></ul></div><div id="PSy3zOFakp" class="relative group/block"><p><strong>VIIRS 10-degree tile scheme</strong></p><img id="HVwZs8ewQs" style="margin:0 auto" src="/example-viewer/build/bea7fd153f489fdbafd4af9f2aca3c43.jpeg" alt="VIIRS tiling scheme.JPG" data-canonical-url="data:image/jpeg;base64,/9j/4AAQSk...KKKKAP/9k="/></div><div id="H8exAVOjTr" class="relative group/block"><h2 id="running-environment" class="relative group"><span class="heading-text">Running environment:</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#running-environment" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><ul><li>This notebook can be run by installing the provided Anaconda Python environment (data/Nightlights/<strong>nightlights-env.yml</strong>).</li></ul></div><div id="UjeyecPH0K" class="relative group/block"><h2 id="importing-python-libraries" class="relative group"><span class="heading-text">Importing Python libraries</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#importing-python-libraries" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="U2oIkDJdlt" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">#Import libraries
import os
import sys
import re
import numpy as np
import rasterio
import rioxarray as rxr
import subprocess
from subprocess import Popen, PIPE
import tempfile
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image
import json
from ipyleaflet import Map, ImageOverlay, basemaps</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="OFDU0IDgIwqS-nrArVGRW" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="E9wnu90ket" class="relative group/block"><h2 id="defining-working-folders" class="relative group"><span class="heading-text">Defining working folders</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#defining-working-folders" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="WZwlTVs6AB" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">input_dir = &quot;input&quot;
input_path = os.path.join(os.getcwd(), &quot;data&quot;, &quot;Nightlights&quot;, input_dir)

output_urban = &quot;output&quot;
urban_path = os.path.join(os.getcwd(), &quot;data&quot;, &quot;Nightlights&quot;, output_urban)

# Create output dir
os.makedirs(urban_path, exist_ok=True)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="j4bY3-C1SNgayVrQC36EH" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="ARYs8oAf5R" class="relative group/block"><h2 id="visualizing-input-data" class="relative group"><span class="heading-text">Visualizing input data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#visualizing-input-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="zeltN8dJ88" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">pattern = re.compile(r&quot;h(\d+)v(\d+)_(\d{4})_(\d)H_median\.tif&quot;)

for root, _, files in os.walk(input_path):
    grouped_files = {}
    
    # Grouping files by h and v
    for file in files:
        match = pattern.match(file)
        if match:
            h, v, year, H = match.groups()
            key = (h, v)
            if key not in grouped_files:
                grouped_files[key] = []
            grouped_files[key].append((year, H, os.path.join(root, file))) 
    
    # Process files for plotting
    for (h, v), file_group in grouped_files.items():
        file_group

tuplelist2dict = {c:{&#x27;year&#x27;:a,&#x27;half&#x27;:b} for a,b,c in file_group}
sorted_dict = {}

grid_tile = None
for item in sorted(tuplelist2dict, key = lambda k: (tuplelist2dict[k][&#x27;year&#x27;], tuplelist2dict[k][&#x27;half&#x27;])):
    sorted_dict.update({item:tuplelist2dict[item]})
    grid_tile = item.split(&#x27;/&#x27;)[-1].split(&#x27;_&#x27;)[0]
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="J_-1MfJ5i_wp7xX-QTvsg" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="QayYfaL1bk" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def plot_figures(figures, nrows = 1, ncols=1, factor = 1., clip_range = None, **kwargs):
    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15, 15))
    for idx,file_name in enumerate(figures):
        title = file_name.split(&#x27;/&#x27;)[-1]
        title = title.replace(&quot;_median.tif&quot;, &quot;&quot;)
        axeslist.ravel()[idx].imshow(np.clip(mpimg.imread(file_name)*factor, *clip_range), **kwargs) # cmap=plt.gray(), cmap=&#x27;Greys&#x27;
        axeslist.ravel()[idx].set_title(title)
        axeslist.ravel()[idx].set_axis_off()
    fig.suptitle(r&#x27;Median nighttime light level [$Wcm^{-2}sr^{-1}$]&#x27;, fontsize=20)
    #plt.tight_layout() 

    </code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="LbG-hWhqrnGEKf5wobnRu" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="khRDUIgypN" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">plot_figures(sorted_dict, 4, 2, clip_range=(0,1), factor=100./255.)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="JTFB0wJBE84Uex47hq3aP" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/example-viewer/build/e28ff140cf45c79316a9514d2838d56a.png" alt="&lt;Figure size 1500x1500 with 8 Axes&gt;"/></div></div><div id="m75yaAPZJa" class="relative group/block"><h2 id="applying-color-blending" class="relative group"><span class="heading-text">Applying color blending</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#applying-color-blending" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="l7c8rPBmJi" class="relative group/block"><p>Additive color blending involves mixing the primary colors of light, red (R), green (G), and blue (B), while adjusting their luminance levels. By manipulating the luminance of these colors, a wide range of hues can be achieved, with the key characteristic being that combining all three colors results in white.</p></div><div id="iICQGUAQYW" class="relative group/block"><p>Technique</p><ul><li>maximum pixel value of images for 2019 (brightest pixel values) is assigned to red (R)</li><li>minimum pixel value of images for 2020-2021 (darkest pixel values) is assigned to green (G)</li><li>maximum pixel value of images for 2022 (brightest pixel values) is assigned to blue (B)</li></ul></div><div id="g3uNQ40B5w" class="relative group/block"><p>Output</p><ul><li>regions where a decrease in nighttime light level occurred are displayed in red</li><li>areas that experienced an increase (presumed to indicate an increase in social activity) are shown in blue</li><li>regions where there was no significant change throughout the pandemic are displayed in a gradient from gray to white.</li></ul></div><div id="YSE8BzT1fa" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">pattern = re.compile(r&quot;h(\d+)v(\d+)_(\d{4})_(\d)H_median\.tif&quot;)


def read_and_preprocess(file):
    with rasterio.open(file) as src:
        img = src.read(1)
        img = np.nan_to_num(img, nan=0)  # Replace NaNs with zeros
        return img, src.profile

    
def additive_blending(grouped_files):
    # Process each group of files for blending
    for (h, v), file_group in grouped_files.items():
        # Initialize arrays to store the maximum and minimum values for each year
        max_2019 = None
        min_2020_2021 = None
        max_2022 = None
        
        for year, H, file in file_group:
            img, profile = read_and_preprocess(file)
            
            if year == &#x27;2019&#x27;:
                if max_2019 is None:
                    max_2019 = img
                else:
                    max_2019 = np.maximum(max_2019, img)
            elif year in [&#x27;2020&#x27;, &#x27;2021&#x27;]:
                if min_2020_2021 is None:
                    min_2020_2021 = img
                else:
                    min_2020_2021 = np.minimum(min_2020_2021, img)
            elif year == &#x27;2022&#x27;:
                if max_2022 is None:
                    max_2022 = img
                else:
                    max_2022 = np.maximum(max_2022, img)
                                  
    # Create the blended image using the specified blending technique
    blended_img = np.zeros((max_2019.shape[0], max_2019.shape[1], 3), dtype=np.float32)
    blended_img[:, :, 0] = max_2019.astype(np.float32)  # Red band: maximum of 2019
    blended_img[:, :, 1] = min_2020_2021.astype(np.float32)  # Green band: minimum of 2020-2021 compared
    blended_img[:, :, 2] = max_2022.astype(np.float32)  # Blue band: maximum of 2022
    
    return blended_img, profile        </code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="1YI2w0gVGHwGlshhoCP0J" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="kppzLqlLSj" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Grouping files per (h,v) tiles and years span
grouped_files = {}
for root, _, files in os.walk(input_path):
    
    
    # Group files by h and v
    for file in files:
        match = pattern.match(file)
        if match:
            h, v, year, H = match.groups()
            key = (h, v)
            if key not in grouped_files:
                grouped_files[key] = []
            grouped_files[key].append((year, H, os.path.join(root, file)))


# blending           
blended_img, profile = additive_blending(grouped_files)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="NjOiUc7eb-4Zwqci0HEk5" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="SS0QKAR4iE" class="relative group/block"><h2 id="employing-urban-stretch-processing" class="relative group"><span class="heading-text">Employing “urban” stretch processing</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#employing-urban-stretch-processing" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="EwHEIK6MSt" class="relative group/block"><p>The purpose of the stretch processing is to emphasize the nighttime light level of each band (corresponding to 2019, 2020-21, and 2022), focusing on:</p><ul><li>“urban” nighttime light levels: the display range of each band is adjusted to 25-1000 [watts·cm-2·sr-1], emphasizing brighter areas</li></ul></div><div id="uitwaXHSW6" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Urban stretch processing: Emphasize brighter areas
def urban_stretch_processing(band):
    min_val = 25
    max_val = 1000
    band = np.clip(band, min_val, max_val)
    band = (band - min_val) / (max_val - min_val) * 255
    return band.astype(np.uint8)

# Apply urban stretch processing to each band
blended_img[:, :, 0] = urban_stretch_processing(blended_img[:, :, 0])
blended_img[:, :, 1] = urban_stretch_processing(blended_img[:, :, 1])
blended_img[:, :, 2] = urban_stretch_processing(blended_img[:, :, 2])
        
# Update the profile for a 3-band image and set nodata value to None
profile.update(count=3, dtype=rasterio.uint8, nodata=None)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="xut_C5gDBWp-nlD4OdPe0" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="rkT1rdlED1" class="relative group/block"><h2 id="plotting-blended-image" class="relative group"><span class="heading-text">Plotting blended image</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#plotting-blended-image" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="OpGuFJqom9" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def plot_image(image, factor=1.0, clip_range = None, **kwargs):
    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))
    if clip_range is not None:
        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)
    else:
        ax.imshow(image * factor, **kwargs)
    ax.set_xticks([])
    ax.set_yticks([])


plot_image(blended_img, factor=1.5/255., clip_range=(0,1))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="gPFfFTSadhil2-XMfd0uI" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><img src="/example-viewer/build/0049010c11ccd43435e422180285ddb2.png" alt="&lt;Figure size 1500x1500 with 1 Axes&gt;"/></div></div><div id="sr5jrdZmxx" class="relative group/block"><h2 id="overlaying-with-an-interactive-map" class="relative group"><span class="heading-text">Overlaying with an interactive map</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#overlaying-with-an-interactive-map" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="eWHKQ8UAcV" class="relative group/block"><p>Saving blended image as Cloud Optimized GeoTIFF</p></div><div id="tK5Hri1O7Q" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Exporting output as COG file 
res_name = f&quot;Nighttimelevel_Urban_{grid_tile}_2019-2022.tif&quot;
output_cog = os.path.join(output_urban, res_name)


# Write the blended image directly to a temporary file
with tempfile.NamedTemporaryFile(suffix=&quot;.tif&quot;) as temp_file:
    with rasterio.open(temp_file.name, &quot;w&quot;, **profile) as dst:
        dst.write(blended_img[:, :, 0], 1)
        dst.write(blended_img[:, :, 1], 2)
        dst.write(blended_img[:, :, 2], 3)

    subprocess.run([
        &quot;gdal_translate&quot;, &quot;-of&quot;, &quot;COG&quot;,
        &quot;-co&quot;, &quot;COMPRESS=DEFLATE&quot;,
        &quot;-co&quot;, &quot;BLOCKSIZE=512&quot;,
        &quot;-co&quot;, &quot;RESAMPLING=NEAREST&quot;,
        &quot;-co&quot;, &quot;OVERVIEWS=IGNORE_EXISTING&quot;,
        temp_file.name,
        output_cog
    ])

print(f&quot;COG file saved as {output_cog}&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Psq495XGhM8YkwRgE2-Li" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>Input file size is 2400, 2400
0...10...20...30...40...50...60...70...80...90...100 - done.
COG file saved as out_urban/Nighttimelevel_Urban_h10v04_2019-2022.tif
</span></code></pre></div></div></div><div id="xvUMuxjZov" class="relative group/block"><p>Extracting bounding-box coordinates</p></div><div id="Picl5hern1" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">p1 = Popen([&quot;gdalinfo&quot;, &quot;-json&quot;, output_cog, &quot;-mm&quot;], stdout=PIPE)
output = p1.communicate()[0]
dec_out = output.decode(&#x27;utf-8&#x27;)
j_str = json.loads(dec_out)
bbox = j_str[&#x27;cornerCoordinates&#x27;]
ll = bbox[&#x27;lowerLeft&#x27;]  # SW coo
ur = bbox[&#x27;upperRight&#x27;] # NE coo
center = bbox[&#x27;center&#x27;]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="BZ-Vu5ghnbbN-1lc9erA9" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="bykHDlUGPk" class="relative group/block"><p>Adding alpha channel to the blended image</p></div><div id="YYjF8ZmJpY" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def almostEquals(a,b,thres=50):
    return all(abs(a[i]-b[i])&lt;thres for i in range(len(a)))


image = Image.open(output_cog).convert(&#x27;RGBA&#x27;)
pixeldata = list(image.getdata())


for i,pixel in enumerate(pixeldata):
    if almostEquals(pixel[:3], (0,0,0)):
        pixeldata[i] = (0,0,0,0)


image.putdata(pixeldata)
png_path = os.path.join(output_urban, res_name.replace(&quot;.tif&quot;,&quot;.png&quot;))
res = image.save(png_path)
#os.path.abspath(res)
abs_path = os.path.abspath(png_path)
work_dir = os.getcwd()
id_ = work_dir.split(&#x27;/&#x27;)[2]
base_url = os.path.join(&#x27;https://hub.eox.at/user&#x27;,id_,&#x27;files&#x27;)
#base_url
abs_path = &#x27;/&#x27;.join(abs_path.split(&#x27;/&#x27;)[3:])
#abs_path
#os.path.join(base_url,abs_path)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Xr79Dth70zwY2Tt74LUHe" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="S3mOjFXvtY" class="relative group/block"><p>Overlay with OpenStreetMap</p></div><div id="EzVRe9MmNL" class="relative group/block"><div class="flex sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:hidden"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm border border-l-4 border-l-blue-400 border-gray-200 dark:border-l-blue-400 dark:border-gray-800"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">m = Map(basemap=basemaps.CartoDB.DarkMatter, center=(center[1], center[0]), zoom=6)
image = ImageOverlay(
        url=os.path.join(base_url,abs_path), #url=&quot;https://hub.eox.at/user/&lt;id&gt;/files/&lt;path_to_png&gt;
        bounds=((ll[1], ll[0]), (ur[1], ur[0])) # SW and NE corners
                    )
m.add_layer(image);
m</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="b-rdIYyswisy5r4hOnZKC" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="H2tdJgWypn" class="relative group/block"><p>Using additive color blending images to focus on urban areas in the northeastern United States, particularly the southern part of the Boston-Washington Corridor comprising major cities like New York, Philadelphia, Baltimore, and Washington, D.C., revealed relatively little variation in nighttime lights before and after the COVID-19 pandemic, as indicated by the images appearing white. However, significant reductions in nighttime lights during the COVID-19 pandemic (subsequently recovering to pre-pandemic levels) were evident in other medium to large cities, including Boston and Toronto, among others, as indicated by the images appearing pink to reddish.</p></div><div id="Uqpwy4TKIi" class="relative group/block"><h2 id="alternative-stretch-processing-approaches" class="relative group"><span class="heading-text">Alternative stretch processing approaches</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#alternative-stretch-processing-approaches" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="FvqkSMXWlH" class="relative group/block"><ul><li>“Rural” nighttime light levels: setting each band’s display range to 0-50 [Watts·cm-2·sr-1] to emphasize darker areas</li><li>For a broader focus (from rural to urban areas): applying a log10 transformation to the values of each band with a display range set to 0-3.6 (equivalent to 0-3981 [Watts·cm-2·sr-1])</li></ul></div><div id="Tc65JoPVF1" class="relative group/block"><h2 id="final-remarks" class="relative group"><span class="heading-text">Final remarks</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#final-remarks" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="nZgN3rzqEf" class="relative group/block"><p>This product has been specifically designed for utilization by researchers in applied scientific fields.
Potential applications are being explored in environmental and social issue studies, such as disaster recovery, energy, urban land use changes, conflicts, migration, and monitoring of illegal, unreported activities.</p></div><div id="huXLkNgKgl" class="relative group/block"><h2 id="to-learn-more" class="relative group"><span class="heading-text">To learn more</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#to-learn-more" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="GrxVMvV6dd" class="relative group/block"><p>The presented approach is often referenced in scientific and public health research. For example, Bunpei Tojo (2021) used Nightlights data in the study “Application of Earth observation satellite data to public health: Comparison of night light (VIIRS) and solar radiation (SGLI) and domestic COVID-19 epidemic,” presented at the 12th Federation of Science and Technology conference, to analyze the relationship between nighttime light intensity and public health factors.
<cite class="" data-state="closed"><a href="https://doi.org/10.11487/oukan.2021.0_B-4-4" target="_blank" rel="noreferrer" class="hover-link">東城 (2021)</a></cite>.</p></div><div></div><section id="references" class="article-grid subgrid-gap col-screen"><div><header class="text-lg font-semibold text-stone-900 dark:text-white group">References<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#references" title="Link to References" aria-label="Link to References">¶</a></header></div><div class="pl-3 mb-8 text-xs text-stone-500 dark:text-stone-300"><ol><li class="break-words" id="cite-2021">東城文柄. (2021). 地球観測衛星データの公衆衛生学への応用. In <i>横幹連合コンファレンス予稿集</i> (No. 0; Vol. 2021). 特定非営利活動法人　横断型基幹科学技術研究団体連合. <a target="_blank" rel="noreferrer" href="https://doi.org/10.11487/oukan.2021.0_B-4-4">10.11487/oukan.2021.0_B-4-4</a></li></ol></div></section></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/example-viewer/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-IZFMW3M4.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/example-viewer/build/root-QGLRP2PL.js"/><link rel="modulepreload" href="/example-viewer/build/_shared/chunk-CB3BH7WY.js"/><link rel="modulepreload" href="/example-viewer/build/routes/$-7JYT5576.js"/><script>window.__remixContext = {"url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/nightlights/night-lights-blending","state":{"loaderData":{"root":{"config":{"version":1,"myst":"1.3.25","options":{"hide_toc":true,"hide_footer_links":true,"folders":true},"nav":[],"actions":[],"projects":[{"subject":"EarthCODE Examples","title":"EarthCODE Examples","description":"Collection of examples relevant to the EarthCODE project","github":"https://github.com/esa-earthcode/example-viewer/","id":"5aa0318b-5bc1-41e2-b1d4-053e8b61961b","exports":[],"bibliography":[],"index":"readme","pages":[{"title":"External Notebooks","level":1},{"title":"Eoxhub Workspaces","level":2},{"title":"Eoxhub Notebooks","level":3},{"title":"Dask Tutorials","level":4},{"slug":"external-notebooks.eoxhub-workspaces.eoxhub-notebooks.dask-tutorials.pangeo-example-wildfires","title":"Scale your processes with Dask - hands on example","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":5},{"title":"Eurodatacube","level":2},{"title":"Notebooks","level":3},{"slug":"external-notebooks.eurodatacube.notebooks.readme","title":"Jupyter notebooks","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":4},{"title":"Notebooks","level":4},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.readme","title":"Euro Data Cube Notebooks","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":5},{"title":"Contributions","level":5},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-ai4arctic-sea-ice","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-biomass-forest-observation-sys","title":"AIREO pilot dataset - Biomass (Forest Observation System)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-cap","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-spacenet7","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aot-covid19","title":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.batch-zarr-output","title":"Generating Zarr data cubes with Sentinel Hub Batch API","description":"","date":"","thumbnail":"/example-viewer/build/68dffbf744fa42f4bf3d35e55684984e.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.client-side-processing-using-mass-sh","title":"Important notes","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.cmems-data-download","title":"Cmems Data Download","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.detect-trucks-sentinel2","title":"Detect Trucks using Sentinel-2 data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.drought-monitoring","title":"Drought impact monitoring platform","description":"","date":"","thumbnail":"/example-viewer/build/ad5c19782b006f72352ae57794305840.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-africa-cube-africa-custom-contest","title":"Custom Script Contest – Urban Growth in Africa","description":"","date":"","thumbnail":"/example-viewer/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-byoc-tutorial","title":"How to bring your own data to EDC: Using Sentinel Hub Python package","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-demo-phi-week-v2","title":"xcube-gen and xcube-geodb Hands-On Workshop Φ-Week 2020","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-geodb-4-eurocrops-demo","title":"Demonstration of Eurocrops data use in geoDB","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-notebook-lstm","title":"South Africa Crop Type Classification on Euro Data Cube (EDC)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-usecase-lpis-crop-type-classification","title":"Important notes","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.eurocrops-crop-classification-example","title":"Crop-classification using Sentinel-2 time-series","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.ghsl-urban-delineation","title":"\u003cb\u003eUrban delineation\u003cb\u003e","description":"","date":"","thumbnail":"/example-viewer/build/7bbf545a5eae1d9ebdb91ae42b261063.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.globalearthmonitor-example","title":"Pre-requisites","description":"","date":"","thumbnail":"/example-viewer/build/205c1ded6bd59771975a9fbd3753fd3b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.gpu-support-eoxhub","title":"GPU-Support on EOxHub","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.gran-chaco-phiweek","title":"ESA EO \\phi- week 2020","description":"","date":"","thumbnail":"/example-viewer/build/80cee7db6cdc7002ceedda5689f889fa.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.howtolulc-batch-updated-210621","title":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.lpis-lulc-slo","title":"LPIS Use Case for Land Use / Land Cover Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.lps2022-leverage-euro-data-cube-services","title":"Living Planet Symposium 2022 Training Session","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.no2-analysis-covid19-lockdowns","title":"Impact of Covid19 induced lockdown on NO2 levels","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.no2-so2-trend-veda-api-igarss-2023","title":"Using the NASA VEDA EOAPI","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.ogc-edc","title":"Important notes","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.openeo-client-demo","title":"openEO Client Demo","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.race-finishedgoodsinventory-inidcator","title":"Finished Goods Inventory indicator for RACE","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.third-party-planetscope","title":"Third Party Data Import - PlanetScope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.xcube-access-datasets","title":"Using xcube to access non-commercial and commercial data sets","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.xcube-viewer-as-a-service-in-edc1","title":"Visualizing data with xcube viewer in EuroDataCube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-evaluation-workshop","title":"DAPA Evaluation Workshop: Introduction \u0026 Documentation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-1-cube-sentinel-2","title":"DAPA Tutorial #1: Cube - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-2-area-sentinel-2","title":"DAPA Tutorial #2: Area - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-3-timeseries-sentinel-2","title":"DAPA Tutorial #3: Timeseries - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-4-value-sentinel-2","title":"DAPA Tutorial #4: Value - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-5-dem","title":"DAPA Tutorial #5: DEM","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.fairicube.fairicube-data-access-demonstration","title":"EDC Sentinel Hub - data access using xcube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-australian-bushfires","title":"Australian Bushfires","description":"","date":"","thumbnail":"/example-viewer/build/ab194b4f8c40a2b9d64d8a85e37ce1fd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["IGARSS-22","EO Dashboard"],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-data-access","title":"Data Access","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-detect-trucks-sentinel2","title":"Truck Detection Exercise","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-lockdown-in-venice","title":"Environmental Impacts of Lockdown in Venice, Italy during 2020","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-nasa-api-lockdown-in-venice","title":"Lockdown in Venice","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-no2-timeseries-analysis","title":"NO2 timeseries analysis","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-timeseries-stac-api-single-vs-multi","title":"Time series using STAC API statistics endpoints","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.nightlights.night-lights-blending","title":"Monitoring socio-economic activities with nighttime light maps","description":"","date":"","thumbnail":"/example-viewer/build/fb2486d4e1708daa94616c6ae8fc4cc9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"title":"Curated","level":5},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.access-iacs-data","title":"How to access IACS Spatial Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-access-cci-data","title":"Access CCI data with xcube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-first-steps","title":"First steps on the Euro Data Cube platform","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-1-manage-datasets-v11","title":"Manage Collections in your GeoDB","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-2-explore-datasets-2","title":"Exploring Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-3-share-datasets1","title":"Sharing Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-access-urban-atlas-data-v1","title":"[xcube-geodb] How to accesss EEA Urban Atlas Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-data-access","title":"EDC Sentinel Hub - data access using xcube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinelhub-datafusion-basic","title":"EDC Sentinel Hub: Data Fusion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinelhub-datafusion-ndvi","title":"EDC Sentinel Hub: Data Fusion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-datasets","title":"EDC Sentinel Hub - using xcube to access different data sets in Sentinel Hub","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-setup","title":"Setup for EDC core API access using xcube client library","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-xcube-integration","title":"EDC Sentinel Hub - XCUBE integration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-usecase-ndvi-timeline","title":"NDVI timeline","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.eo-learn","title":"Using eo-learn in EDC: a starter’s guide.","description":"","date":"","thumbnail":"/example-viewer/build/5a1f8475f0c3652f4630d03d72891b98.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.esdl-edc-v0-2","title":"Earth System Data Lab Tutorial @ Euro Data Cube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.exploring-time-and-space-with-edc","title":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.how-to-access-dem-data-through-sentinel-hub-api","title":"How to access DEM data through Sentinel Hub API","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.sentinelhub-py","title":"Using Sentinel Hub Process API in EDC: a starter’s guide.","description":"","date":"","thumbnail":"/example-viewer/build/01e22903839391bc356ac886ec2b2fa7.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/example-viewer"},"routes/$":{"config":{"version":1,"myst":"1.3.25","options":{"hide_toc":true,"hide_footer_links":true,"folders":true},"nav":[],"actions":[],"projects":[{"subject":"EarthCODE Examples","title":"EarthCODE Examples","description":"Collection of examples relevant to the EarthCODE project","github":"https://github.com/esa-earthcode/example-viewer/","id":"5aa0318b-5bc1-41e2-b1d4-053e8b61961b","exports":[],"bibliography":[],"index":"readme","pages":[{"title":"External Notebooks","level":1},{"title":"Eoxhub Workspaces","level":2},{"title":"Eoxhub Notebooks","level":3},{"title":"Dask Tutorials","level":4},{"slug":"external-notebooks.eoxhub-workspaces.eoxhub-notebooks.dask-tutorials.pangeo-example-wildfires","title":"Scale your processes with Dask - hands on example","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":5},{"title":"Eurodatacube","level":2},{"title":"Notebooks","level":3},{"slug":"external-notebooks.eurodatacube.notebooks.readme","title":"Jupyter notebooks","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":4},{"title":"Notebooks","level":4},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.readme","title":"Euro Data Cube Notebooks","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":5},{"title":"Contributions","level":5},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-ai4arctic-sea-ice","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-biomass-forest-observation-sys","title":"AIREO pilot dataset - Biomass (Forest Observation System)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-cap","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-spacenet7","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aot-covid19","title":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.batch-zarr-output","title":"Generating Zarr data cubes with Sentinel Hub Batch API","description":"","date":"","thumbnail":"/example-viewer/build/68dffbf744fa42f4bf3d35e55684984e.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.client-side-processing-using-mass-sh","title":"Important notes","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.cmems-data-download","title":"Cmems Data Download","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.detect-trucks-sentinel2","title":"Detect Trucks using Sentinel-2 data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.drought-monitoring","title":"Drought impact monitoring platform","description":"","date":"","thumbnail":"/example-viewer/build/ad5c19782b006f72352ae57794305840.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-africa-cube-africa-custom-contest","title":"Custom Script Contest – Urban Growth in Africa","description":"","date":"","thumbnail":"/example-viewer/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-byoc-tutorial","title":"How to bring your own data to EDC: Using Sentinel Hub Python package","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-demo-phi-week-v2","title":"xcube-gen and xcube-geodb Hands-On Workshop Φ-Week 2020","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-geodb-4-eurocrops-demo","title":"Demonstration of Eurocrops data use in geoDB","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-notebook-lstm","title":"South Africa Crop Type Classification on Euro Data Cube (EDC)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-usecase-lpis-crop-type-classification","title":"Important notes","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.eurocrops-crop-classification-example","title":"Crop-classification using Sentinel-2 time-series","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.ghsl-urban-delineation","title":"\u003cb\u003eUrban delineation\u003cb\u003e","description":"","date":"","thumbnail":"/example-viewer/build/7bbf545a5eae1d9ebdb91ae42b261063.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.globalearthmonitor-example","title":"Pre-requisites","description":"","date":"","thumbnail":"/example-viewer/build/205c1ded6bd59771975a9fbd3753fd3b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.gpu-support-eoxhub","title":"GPU-Support on EOxHub","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.gran-chaco-phiweek","title":"ESA EO \\phi- week 2020","description":"","date":"","thumbnail":"/example-viewer/build/80cee7db6cdc7002ceedda5689f889fa.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.howtolulc-batch-updated-210621","title":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.lpis-lulc-slo","title":"LPIS Use Case for Land Use / Land Cover Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.lps2022-leverage-euro-data-cube-services","title":"Living Planet Symposium 2022 Training Session","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.no2-analysis-covid19-lockdowns","title":"Impact of Covid19 induced lockdown on NO2 levels","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.no2-so2-trend-veda-api-igarss-2023","title":"Using the NASA VEDA EOAPI","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.ogc-edc","title":"Important notes","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.openeo-client-demo","title":"openEO Client Demo","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.race-finishedgoodsinventory-inidcator","title":"Finished Goods Inventory indicator for RACE","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.third-party-planetscope","title":"Third Party Data Import - PlanetScope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.xcube-access-datasets","title":"Using xcube to access non-commercial and commercial data sets","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.xcube-viewer-as-a-service-in-edc1","title":"Visualizing data with xcube viewer in EuroDataCube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-evaluation-workshop","title":"DAPA Evaluation Workshop: Introduction \u0026 Documentation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-1-cube-sentinel-2","title":"DAPA Tutorial #1: Cube - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-2-area-sentinel-2","title":"DAPA Tutorial #2: Area - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-3-timeseries-sentinel-2","title":"DAPA Tutorial #3: Timeseries - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-4-value-sentinel-2","title":"DAPA Tutorial #4: Value - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-5-dem","title":"DAPA Tutorial #5: DEM","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.fairicube.fairicube-data-access-demonstration","title":"EDC Sentinel Hub - data access using xcube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-australian-bushfires","title":"Australian Bushfires","description":"","date":"","thumbnail":"/example-viewer/build/ab194b4f8c40a2b9d64d8a85e37ce1fd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["IGARSS-22","EO Dashboard"],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-data-access","title":"Data Access","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-detect-trucks-sentinel2","title":"Truck Detection Exercise","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-lockdown-in-venice","title":"Environmental Impacts of Lockdown in Venice, Italy during 2020","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-nasa-api-lockdown-in-venice","title":"Lockdown in Venice","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-no2-timeseries-analysis","title":"NO2 timeseries analysis","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-timeseries-stac-api-single-vs-multi","title":"Time series using STAC API statistics endpoints","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.nightlights.night-lights-blending","title":"Monitoring socio-economic activities with nighttime light maps","description":"","date":"","thumbnail":"/example-viewer/build/fb2486d4e1708daa94616c6ae8fc4cc9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"title":"Curated","level":5},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.access-iacs-data","title":"How to access IACS Spatial Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-access-cci-data","title":"Access CCI data with xcube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-first-steps","title":"First steps on the Euro Data Cube platform","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-1-manage-datasets-v11","title":"Manage Collections in your GeoDB","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-2-explore-datasets-2","title":"Exploring Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-3-share-datasets1","title":"Sharing Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-access-urban-atlas-data-v1","title":"[xcube-geodb] How to accesss EEA Urban Atlas Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-data-access","title":"EDC Sentinel Hub - data access using xcube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinelhub-datafusion-basic","title":"EDC Sentinel Hub: Data Fusion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinelhub-datafusion-ndvi","title":"EDC Sentinel Hub: Data Fusion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-datasets","title":"EDC Sentinel Hub - using xcube to access different data sets in Sentinel Hub","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-setup","title":"Setup for EDC core API access using xcube client library","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-xcube-integration","title":"EDC Sentinel Hub - XCUBE integration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-usecase-ndvi-timeline","title":"NDVI timeline","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.eo-learn","title":"Using eo-learn in EDC: a starter’s guide.","description":"","date":"","thumbnail":"/example-viewer/build/5a1f8475f0c3652f4630d03d72891b98.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.esdl-edc-v0-2","title":"Earth System Data Lab Tutorial @ Euro Data Cube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.exploring-time-and-space-with-edc","title":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.how-to-access-dem-data-through-sentinel-hub-api","title":"How to access DEM data through Sentinel Hub API","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.sentinelhub-py","title":"Using Sentinel Hub Process API in EDC: a starter’s guide.","description":"","date":"","thumbnail":"/example-viewer/build/01e22903839391bc356ac886ec2b2fa7.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6}]}]},"page":{"version":1,"kind":"Notebook","sha256":"bd7810c7df99349ad124315723cbf5e675b815c4ed122104dcd32ac0a90b64ad","slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.nightlights.night-lights-blending","location":"/external_notebooks/eurodatacube/notebooks/notebooks/contributions/NightLights/Night_Lights_Blending.ipynb","dependencies":[],"frontmatter":{"title":"Monitoring socio-economic activities with nighttime light maps","content_includes_title":true,"kernelspec":{"name":"conda-env-users-edc-2025.01-01-py","display_name":"users-edc-2025.01-01","language":"python"},"github":"https://github.com/esa-earthcode/example-viewer/","subject":"EarthCODE Examples","numbering":{"title":{"offset":5}},"edit_url":"https://github.com/esa-earthcode/example-viewer//blob/main/external_notebooks/eurodatacube/notebooks/notebooks/contributions/NightLights/Night_Lights_Blending.ipynb","thumbnail":"/example-viewer/build/fb2486d4e1708daa94616c6ae8fc4cc9.jpeg","exports":[{"format":"ipynb","filename":"Night_Lights_Blending.ipynb","url":"/example-viewer/build/Night_Lights_Blendin-113f9a37c33c168110b686786b6ff2ca.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":1,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Monitoring socio-economic activities with nighttime light maps","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LM9Ov00iBD"}],"identifier":"monitoring-socio-economic-activities-with-nighttime-light-maps","label":"Monitoring socio-economic activities with nighttime light maps","html_id":"monitoring-socio-economic-activities-with-nighttime-light-maps","implicit":true,"key":"UgZb0DHoWL"},{"type":"heading","depth":2,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Case study: Creating nighttime light maps with color blending","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ktzVv8joqO"}],"identifier":"case-study-creating-nighttime-light-maps-with-color-blending","label":"Case study: Creating nighttime light maps with color blending","html_id":"case-study-creating-nighttime-light-maps-with-color-blending","implicit":true,"key":"CLWn3dZQal"}],"key":"jTGnI5dJyT"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"This notebook demonstrates how to create nighttime light variation maps over a time interval (from 2019 to 2022) with additive color blending for studying the distribution of artificial lighting in urban and rural regions, offering insights into urbanization, infrastructure development, and socio-economic activity.\nThe Nighttime Light Levels indicator can be explored on the EO Dashboard by selecting the EXPLORE DATASETS mode and choosing ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oKjVB4BAT2"},{"type":"link","url":"https://eodashboard.org/explore?indicator=NTLU\u0026x=12142837.23019\u0026y=4137471.98879\u0026z=5.69238","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Night lights indicators","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WWlWvsguvJ"}],"urlSource":"https://eodashboard.org/explore?indicator=NTLU\u0026x=12142837.23019\u0026y=4137471.98879\u0026z=5.69238","key":"YgHR1DNv1u"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TGaPBfrWHN"}],"key":"JhXQivBDt7"},{"type":"paragraph","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"The study has been carried out by ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"c5JrmU5Lff"},{"type":"strong","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Bumpei Tojo PhD (Associate Professor), School of International and Area Studies, Tokyo University of Foreign Studies, Japan","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"pLyflo6Srd"}],"key":"eRkkOIthgw"},{"type":"text","value":".","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"QwJsb6m4Zn"}],"key":"p0Pzz5Z7ld"},{"type":"paragraph","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"RtA6FvAgfP"},{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"PLES Engineering team","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"berFWY2uVs"}],"key":"fDTrdeB5oP"},{"type":"text","value":" (supporting ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"zdJC8Q9vrd"},{"type":"emphasis","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"ESA Green Solutions Division","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Ys0tCsfs1x"}],"key":"lg8GGOshQG"},{"type":"text","value":", EOP-SG) developed the blending algorithm with the current Notebook implementation and data ingestion on the dashboard (contacts: ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"HNn19S9GpV"},{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Federico Rondoni","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"cji1KEsHJ4"}],"key":"sDz4tRhFp4"},{"type":"text","value":", ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"WHef07YI5I"},{"type":"link","url":"mailto:f.rondoni@stariongroup.eu","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"f​.rondoni@stariongroup​.eu","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"AAc2jX9K8Q"}],"urlSource":"mailto:f.rondoni@stariongroup.eu","key":"YA7LjD0bBA"},{"type":"text","value":", ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"zO8jcDtxkg"},{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Diego Moglioni","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"BpSwWupVH0"}],"key":"Sntc5IM6mS"},{"type":"text","value":", ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"M1PrSua90B"},{"type":"link","url":"mailto:d.moglioni@stariongroup.eu","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"d​.moglioni@stariongroup​.eu","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"HAzeBy2G3K"}],"urlSource":"mailto:d.moglioni@stariongroup.eu","key":"J9uom8cRlb"},{"type":"text","value":").","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"pBGrkffDgb"}],"key":"L4bxMlmp2U"}],"key":"hZNBR93C9U"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"image","url":"/example-viewer/build/fb2486d4e1708daa94616c6ae8fc4cc9.jpeg","alt":"title","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EdayEuiaMv","urlSource":"data:image/jpeg;base64,/9j/4AAQSk...YkVWooA//Z"},{"type":"text","value":"\nExample of a nighttime light map covering Northeastern United States during 2019-2022, representing areas where a decrease in nighttime light level occurred (indicating a presumed reduction in social activity) in red, and areas where an increase occurred (indicating a presumed increase in social activity) in blue.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xlRZxC7pNl"}],"key":"iPnUjzp14t"}],"key":"ZMstn06VYS"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Input data:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SHpZsvyeup"}],"identifier":"input-data","label":"Input data:","html_id":"input-data","implicit":true,"key":"srpnPSSkQW"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"This product was developed by JAXA by aggregating the data from the Visible Infrared Imaging Radiometer Suite (VIIRS, onboard the Suomi NPP satellite) on a semi-annual basis (using median image generation) with 10-degree lat/lon (geographic) grid h-v tile as Geo Tiff files.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"levKqEDmCe"}],"key":"sCTUD9hKhX"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The tiles are 2400 x 2400 pixels, with pixel size of 0.004166 degrees (~464 m at the equator).","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"aPXioruNOE"}],"key":"V1PMeL8SFM"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Metric: nighttime radiance (measured in watts per square centimeter per steradian, [W/cm²/sr]), which represents the brightness of artificial lighting.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"uJe5mkT6rU"}],"key":"kPyqrrhIsP"}],"key":"qeXNbobBuz"}],"key":"Mix4ftCiFF"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"strong","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"VIIRS 10-degree tile scheme","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"O02roEdx8m"}],"key":"eppncMB3YT"}],"key":"pxC9DF0UgD"},{"type":"image","url":"/example-viewer/build/bea7fd153f489fdbafd4af9f2aca3c43.jpeg","alt":"VIIRS tiling scheme.JPG","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HVwZs8ewQs","urlSource":"data:image/jpeg;base64,/9j/4AAQSk...KKKKAP/9k="}],"key":"PSy3zOFakp"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Running environment:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"d1SxrA7x3i"}],"identifier":"running-environment","label":"Running environment:","html_id":"running-environment","implicit":true,"key":"wywuODMvmX"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"This notebook can be run by installing the provided Anaconda Python environment (data/Nightlights/","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"VJkQxVbZgl"},{"type":"strong","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"nightlights-env.yml","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"EAvVV03RVj"}],"key":"oG70NOAUk4"},{"type":"text","value":").","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"XFdH1wdVJg"}],"key":"Ajiq7Xhd5G"}],"key":"ugvGF2ebGK"}],"key":"H8exAVOjTr"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Importing Python libraries","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vJSCwnCjqN"}],"identifier":"importing-python-libraries","label":"Importing Python libraries","html_id":"importing-python-libraries","implicit":true,"key":"vDE31gbtsc"}],"key":"UjeyecPH0K"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"#Import libraries\nimport os\nimport sys\nimport re\nimport numpy as np\nimport rasterio\nimport rioxarray as rxr\nimport subprocess\nfrom subprocess import Popen, PIPE\nimport tempfile\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom PIL import Image\nimport json\nfrom ipyleaflet import Map, ImageOverlay, basemaps","key":"mTiXJRNIRX"},{"type":"output","id":"OFDU0IDgIwqS-nrArVGRW","data":[],"key":"ZUtU5lhOox"}],"key":"U2oIkDJdlt"},{"type":"block","kind":"notebook-content","data":{"tags":[]},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Defining working folders","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uONaGqcwVy"}],"identifier":"defining-working-folders","label":"Defining working folders","html_id":"defining-working-folders","implicit":true,"key":"Hd4nISEtKy"}],"visibility":"show","key":"E9wnu90ket"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"input_dir = \"input\"\ninput_path = os.path.join(os.getcwd(), \"data\", \"Nightlights\", input_dir)\n\noutput_urban = \"output\"\nurban_path = os.path.join(os.getcwd(), \"data\", \"Nightlights\", output_urban)\n\n# Create output dir\nos.makedirs(urban_path, exist_ok=True)","visibility":"show","key":"VVmxe355ks"},{"type":"output","id":"j4bY3-C1SNgayVrQC36EH","data":[],"visibility":"show","key":"Lc9wdr5J1Y"}],"visibility":"show","key":"WZwlTVs6AB"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Visualizing input data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MoqzXgWBi1"}],"identifier":"visualizing-input-data","label":"Visualizing input data","html_id":"visualizing-input-data","implicit":true,"key":"riRQ0cCtgB"}],"key":"ARYs8oAf5R"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"pattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\nfor root, _, files in os.walk(input_path):\n    grouped_files = {}\n    \n    # Grouping files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file))) \n    \n    # Process files for plotting\n    for (h, v), file_group in grouped_files.items():\n        file_group\n\ntuplelist2dict = {c:{'year':a,'half':b} for a,b,c in file_group}\nsorted_dict = {}\n\ngrid_tile = None\nfor item in sorted(tuplelist2dict, key = lambda k: (tuplelist2dict[k]['year'], tuplelist2dict[k]['half'])):\n    sorted_dict.update({item:tuplelist2dict[item]})\n    grid_tile = item.split('/')[-1].split('_')[0]\n","visibility":"show","key":"spK2WGCu1G"},{"type":"output","id":"J_-1MfJ5i_wp7xX-QTvsg","data":[],"visibility":"show","key":"thejdX5dfl"}],"visibility":"show","key":"zeltN8dJ88"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def plot_figures(figures, nrows = 1, ncols=1, factor = 1., clip_range = None, **kwargs):\n    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(15, 15))\n    for idx,file_name in enumerate(figures):\n        title = file_name.split('/')[-1]\n        title = title.replace(\"_median.tif\", \"\")\n        axeslist.ravel()[idx].imshow(np.clip(mpimg.imread(file_name)*factor, *clip_range), **kwargs) # cmap=plt.gray(), cmap='Greys'\n        axeslist.ravel()[idx].set_title(title)\n        axeslist.ravel()[idx].set_axis_off()\n    fig.suptitle(r'Median nighttime light level [$Wcm^{-2}sr^{-1}$]', fontsize=20)\n    #plt.tight_layout() \n\n    ","visibility":"show","key":"eKynRYZvSC"},{"type":"output","id":"LbG-hWhqrnGEKf5wobnRu","data":[],"visibility":"show","key":"nXyEyonXxu"}],"visibility":"show","key":"QayYfaL1bk"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"plot_figures(sorted_dict, 4, 2, clip_range=(0,1), factor=100./255.)","visibility":"show","key":"c1xE2EANP8"},{"type":"output","id":"JTFB0wJBE84Uex47hq3aP","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"e28ff140cf45c79316a9514d2838d56a","path":"/example-viewer/build/e28ff140cf45c79316a9514d2838d56a.png"},"text/plain":{"content":"\u003cFigure size 1500x1500 with 8 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"lUkUotODtT"}],"visibility":"show","key":"khRDUIgypN"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Applying color blending","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iHJ4v1YOXG"}],"identifier":"applying-color-blending","label":"Applying color blending","html_id":"applying-color-blending","implicit":true,"key":"gP9CuhyeTN"}],"key":"m75yaAPZJa"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Additive color blending involves mixing the primary colors of light, red (R), green (G), and blue (B), while adjusting their luminance levels. By manipulating the luminance of these colors, a wide range of hues can be achieved, with the key characteristic being that combining all three colors results in white.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GSM5wnmuWj"}],"key":"hFSJmGjdsq"}],"key":"l7c8rPBmJi"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Technique","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"omjEi3Xscn"}],"key":"vFKoHaHqkp"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"maximum pixel value of images for 2019 (brightest pixel values) is assigned to red (R)","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"jfo9FfWZCS"}],"key":"UMZ6vTpVbB"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"minimum pixel value of images for 2020-2021 (darkest pixel values) is assigned to green (G)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"rvHWJ6esch"}],"key":"CDACWMivs4"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"maximum pixel value of images for 2022 (brightest pixel values) is assigned to blue (B)","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"a2qcRd4B7b"}],"key":"RpEFkA5lSN"}],"key":"Y0FGFvOMuR"}],"key":"iICQGUAQYW"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Output","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"V5tHOB6rTs"}],"key":"T4lF9j4B7V"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"regions where a decrease in nighttime light level occurred are displayed in red","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"TDT7Xsdslh"}],"key":"r8m46bSHxZ"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"areas that experienced an increase (presumed to indicate an increase in social activity) are shown in blue","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"rUDj37uyaG"}],"key":"Slwrj5JObc"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"regions where there was no significant change throughout the pandemic are displayed in a gradient from gray to white.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"xmuTQocGaq"}],"key":"AmYEyRQpDL"}],"key":"qRz0pgQ1RT"}],"key":"g3uNQ40B5w"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"pattern = re.compile(r\"h(\\d+)v(\\d+)_(\\d{4})_(\\d)H_median\\.tif\")\n\n\ndef read_and_preprocess(file):\n    with rasterio.open(file) as src:\n        img = src.read(1)\n        img = np.nan_to_num(img, nan=0)  # Replace NaNs with zeros\n        return img, src.profile\n\n    \ndef additive_blending(grouped_files):\n    # Process each group of files for blending\n    for (h, v), file_group in grouped_files.items():\n        # Initialize arrays to store the maximum and minimum values for each year\n        max_2019 = None\n        min_2020_2021 = None\n        max_2022 = None\n        \n        for year, H, file in file_group:\n            img, profile = read_and_preprocess(file)\n            \n            if year == '2019':\n                if max_2019 is None:\n                    max_2019 = img\n                else:\n                    max_2019 = np.maximum(max_2019, img)\n            elif year in ['2020', '2021']:\n                if min_2020_2021 is None:\n                    min_2020_2021 = img\n                else:\n                    min_2020_2021 = np.minimum(min_2020_2021, img)\n            elif year == '2022':\n                if max_2022 is None:\n                    max_2022 = img\n                else:\n                    max_2022 = np.maximum(max_2022, img)\n                                  \n    # Create the blended image using the specified blending technique\n    blended_img = np.zeros((max_2019.shape[0], max_2019.shape[1], 3), dtype=np.float32)\n    blended_img[:, :, 0] = max_2019.astype(np.float32)  # Red band: maximum of 2019\n    blended_img[:, :, 1] = min_2020_2021.astype(np.float32)  # Green band: minimum of 2020-2021 compared\n    blended_img[:, :, 2] = max_2022.astype(np.float32)  # Blue band: maximum of 2022\n    \n    return blended_img, profile        ","key":"qm0sueKSmt"},{"type":"output","id":"1YI2w0gVGHwGlshhoCP0J","data":[],"key":"bwA1CtZFwW"}],"key":"YSE8BzT1fa"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Grouping files per (h,v) tiles and years span\ngrouped_files = {}\nfor root, _, files in os.walk(input_path):\n    \n    \n    # Group files by h and v\n    for file in files:\n        match = pattern.match(file)\n        if match:\n            h, v, year, H = match.groups()\n            key = (h, v)\n            if key not in grouped_files:\n                grouped_files[key] = []\n            grouped_files[key].append((year, H, os.path.join(root, file)))\n\n\n# blending           \nblended_img, profile = additive_blending(grouped_files)","visibility":"show","key":"SHoBy5UfI1"},{"type":"output","id":"NjOiUc7eb-4Zwqci0HEk5","data":[],"visibility":"show","key":"CEaZlZ8jF2"}],"visibility":"show","key":"kppzLqlLSj"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Employing “urban” stretch processing","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xMrO0G6YKV"}],"identifier":"employing-urban-stretch-processing","label":"Employing “urban” stretch processing","html_id":"employing-urban-stretch-processing","implicit":true,"key":"YxVVaZwRdV"}],"key":"SS0QKAR4iE"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The purpose of the stretch processing is to emphasize the nighttime light level of each band (corresponding to 2019, 2020-21, and 2022), focusing on:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gOox5z8Cgk"}],"key":"PkXJIdIbok"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"“urban” nighttime light levels: the display range of each band is adjusted to 25-1000 [watts·cm-2·sr-1], emphasizing brighter areas","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Upscw3IweT"}],"key":"cYE57gsi0l"}],"key":"fPcfgWGSMY"}],"key":"EwHEIK6MSt"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Urban stretch processing: Emphasize brighter areas\ndef urban_stretch_processing(band):\n    min_val = 25\n    max_val = 1000\n    band = np.clip(band, min_val, max_val)\n    band = (band - min_val) / (max_val - min_val) * 255\n    return band.astype(np.uint8)\n\n# Apply urban stretch processing to each band\nblended_img[:, :, 0] = urban_stretch_processing(blended_img[:, :, 0])\nblended_img[:, :, 1] = urban_stretch_processing(blended_img[:, :, 1])\nblended_img[:, :, 2] = urban_stretch_processing(blended_img[:, :, 2])\n        \n# Update the profile for a 3-band image and set nodata value to None\nprofile.update(count=3, dtype=rasterio.uint8, nodata=None)","visibility":"show","key":"uApjudkbju"},{"type":"output","id":"xut_C5gDBWp-nlD4OdPe0","data":[],"visibility":"show","key":"vfkDtFeTxZ"}],"visibility":"show","key":"uitwaXHSW6"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Plotting blended image","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XlLc9sU1jd"}],"identifier":"plotting-blended-image","label":"Plotting blended image","html_id":"plotting-blended-image","implicit":true,"key":"HrmjwgxFAv"}],"key":"rkT1rdlED1"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def plot_image(image, factor=1.0, clip_range = None, **kwargs):\n    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 15))\n    if clip_range is not None:\n        ax.imshow(np.clip(image * factor, *clip_range), **kwargs)\n    else:\n        ax.imshow(image * factor, **kwargs)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n\nplot_image(blended_img, factor=1.5/255., clip_range=(0,1))","visibility":"show","key":"z3WFZxiuLj"},{"type":"output","id":"gPFfFTSadhil2-XMfd0uI","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"0049010c11ccd43435e422180285ddb2","path":"/example-viewer/build/0049010c11ccd43435e422180285ddb2.png"},"text/plain":{"content":"\u003cFigure size 1500x1500 with 1 Axes\u003e","content_type":"text/plain"}}}],"visibility":"show","key":"TbMVMyRAtz"}],"visibility":"show","key":"OpGuFJqom9"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Overlaying with an interactive map","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Zde5QIj8XQ"}],"identifier":"overlaying-with-an-interactive-map","label":"Overlaying with an interactive map","html_id":"overlaying-with-an-interactive-map","implicit":true,"key":"KS4qUGYl6T"}],"key":"sr5jrdZmxx"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Saving blended image as Cloud Optimized GeoTIFF","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TwmK07mGl1"}],"key":"pqTRNld36a"}],"key":"eWHKQ8UAcV"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Exporting output as COG file \nres_name = f\"Nighttimelevel_Urban_{grid_tile}_2019-2022.tif\"\noutput_cog = os.path.join(output_urban, res_name)\n\n\n# Write the blended image directly to a temporary file\nwith tempfile.NamedTemporaryFile(suffix=\".tif\") as temp_file:\n    with rasterio.open(temp_file.name, \"w\", **profile) as dst:\n        dst.write(blended_img[:, :, 0], 1)\n        dst.write(blended_img[:, :, 1], 2)\n        dst.write(blended_img[:, :, 2], 3)\n\n    subprocess.run([\n        \"gdal_translate\", \"-of\", \"COG\",\n        \"-co\", \"COMPRESS=DEFLATE\",\n        \"-co\", \"BLOCKSIZE=512\",\n        \"-co\", \"RESAMPLING=NEAREST\",\n        \"-co\", \"OVERVIEWS=IGNORE_EXISTING\",\n        temp_file.name,\n        output_cog\n    ])\n\nprint(f\"COG file saved as {output_cog}\")","visibility":"show","key":"Q8kkZAN346"},{"type":"output","id":"Psq495XGhM8YkwRgE2-Li","data":[{"name":"stdout","output_type":"stream","text":"Input file size is 2400, 2400\n0...10...20...30...40...50...60...70...80...90...100 - done.\nCOG file saved as out_urban/Nighttimelevel_Urban_h10v04_2019-2022.tif\n"}],"visibility":"show","key":"pln072Urlp"}],"visibility":"show","key":"tK5Hri1O7Q"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Extracting bounding-box coordinates","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uvPPCYt2xy"}],"key":"ydvvhEpwZP"}],"key":"xvUMuxjZov"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"p1 = Popen([\"gdalinfo\", \"-json\", output_cog, \"-mm\"], stdout=PIPE)\noutput = p1.communicate()[0]\ndec_out = output.decode('utf-8')\nj_str = json.loads(dec_out)\nbbox = j_str['cornerCoordinates']\nll = bbox['lowerLeft']  # SW coo\nur = bbox['upperRight'] # NE coo\ncenter = bbox['center']","visibility":"show","key":"AgDsmiFYdd"},{"type":"output","id":"BZ-Vu5ghnbbN-1lc9erA9","data":[],"visibility":"show","key":"RVYx8fpq1N"}],"visibility":"show","key":"Picl5hern1"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Adding alpha channel to the blended image","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xJqYPNP0Yo"}],"key":"VLd3UHtz9T"}],"key":"bykHDlUGPk"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def almostEquals(a,b,thres=50):\n    return all(abs(a[i]-b[i])\u003cthres for i in range(len(a)))\n\n\nimage = Image.open(output_cog).convert('RGBA')\npixeldata = list(image.getdata())\n\n\nfor i,pixel in enumerate(pixeldata):\n    if almostEquals(pixel[:3], (0,0,0)):\n        pixeldata[i] = (0,0,0,0)\n\n\nimage.putdata(pixeldata)\npng_path = os.path.join(output_urban, res_name.replace(\".tif\",\".png\"))\nres = image.save(png_path)\n#os.path.abspath(res)\nabs_path = os.path.abspath(png_path)\nwork_dir = os.getcwd()\nid_ = work_dir.split('/')[2]\nbase_url = os.path.join('https://hub.eox.at/user',id_,'files')\n#base_url\nabs_path = '/'.join(abs_path.split('/')[3:])\n#abs_path\n#os.path.join(base_url,abs_path)","visibility":"show","key":"jLuWNG0yna"},{"type":"output","id":"Xr79Dth70zwY2Tt74LUHe","data":[],"visibility":"show","key":"duBKk0KpXZ"}],"visibility":"show","key":"YYjF8ZmJpY"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Overlay with OpenStreetMap","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KQvVkZoXkV"}],"key":"v0dl5Nr6MB"}],"key":"S3mOjFXvtY"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"m = Map(basemap=basemaps.CartoDB.DarkMatter, center=(center[1], center[0]), zoom=6)\nimage = ImageOverlay(\n        url=os.path.join(base_url,abs_path), #url=\"https://hub.eox.at/user/\u003cid\u003e/files/\u003cpath_to_png\u003e\n        bounds=((ll[1], ll[0]), (ur[1], ur[0])) # SW and NE corners\n                    )\nm.add_layer(image);\nm","visibility":"show","key":"JV15UOHzF3"},{"type":"output","id":"b-rdIYyswisy5r4hOnZKC","data":[{"output_type":"execute_result","execution_count":81,"metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"c690d4c7c957458289f8f9bf72f2e2d1\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"text/plain":{"content":"Map(center=[45.0, -75.0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_ou…","content_type":"text/plain"}}}],"visibility":"show","key":"veRdbn8Tsb"}],"visibility":"show","key":"EzVRe9MmNL"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Using additive color blending images to focus on urban areas in the northeastern United States, particularly the southern part of the Boston-Washington Corridor comprising major cities like New York, Philadelphia, Baltimore, and Washington, D.C., revealed relatively little variation in nighttime lights before and after the COVID-19 pandemic, as indicated by the images appearing white. However, significant reductions in nighttime lights during the COVID-19 pandemic (subsequently recovering to pre-pandemic levels) were evident in other medium to large cities, including Boston and Toronto, among others, as indicated by the images appearing pink to reddish.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nqCJA7kY9m"}],"key":"RQZP2rIdRe"}],"key":"H2tdJgWypn"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Alternative stretch processing approaches","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ExGNLZ7GyQ"}],"identifier":"alternative-stretch-processing-approaches","label":"Alternative stretch processing approaches","html_id":"alternative-stretch-processing-approaches","implicit":true,"key":"EQLbk0xGFY"}],"key":"Uqpwy4TKIi"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"“Rural” nighttime light levels: setting each band’s display range to 0-50 [Watts·cm-2·sr-1] to emphasize darker areas","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mrcdWx0HG1"}],"key":"EhiMKc0XZ5"},{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"For a broader focus (from rural to urban areas): applying a log10 transformation to the values of each band with a display range set to 0-3.6 (equivalent to 0-3981 [Watts·cm-2·sr-1])","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"bQ6HOUtvsO"}],"key":"jlUN0adYKL"}],"key":"yWXCRBYYVB"}],"key":"FvqkSMXWlH"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Final remarks","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"A23nGKZxyX"}],"identifier":"final-remarks","label":"Final remarks","html_id":"final-remarks","implicit":true,"key":"WggjiH01a1"}],"key":"Tc65JoPVF1"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"This product has been specifically designed for utilization by researchers in applied scientific fields.\nPotential applications are being explored in environmental and social issue studies, such as disaster recovery, energy, urban land use changes, conflicts, migration, and monitoring of illegal, unreported activities.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DTPvDidEzp"}],"key":"aIHlYBVxo7"}],"key":"nZgN3rzqEf"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To learn more","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fEDcQddXMz"}],"identifier":"to-learn-more","label":"To learn more","html_id":"to-learn-more","implicit":true,"key":"m2SxVPPJXk"}],"key":"huXLkNgKgl"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"The presented approach is often referenced in scientific and public health research. For example, Bunpei Tojo (2021) used Nightlights data in the study “Application of Earth observation satellite data to public health: Comparison of night light (VIIRS) and solar radiation (SGLI) and domestic COVID-19 epidemic,” presented at the 12th Federation of Science and Technology conference, to analyze the relationship between nighttime light intensity and public health factors.\n","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gr5wYLD9jN"},{"type":"cite","url":"https://doi.org/10.11487/oukan.2021.0_B-4-4","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"東城 (2021)","key":"GZeB15BoUV"}],"kind":"narrative","label":"2021","identifier":"https://doi.org/10.11487/oukan.2021.0_B-4-4","enumerator":"1","key":"cFcLkg4T0a"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"h1mesQFzhf"}],"key":"sxzAH3jmnk"}],"key":"GrxVMvV6dd"}],"key":"JI74AXQBUa"},"references":{"cite":{"order":["2021"],"data":{"2021":{"label":"2021","enumerator":"1","doi":"10.11487/oukan.2021.0_B-4-4","html":"東城文柄. (2021). 地球観測衛星データの公衆衛生学への応用. In \u003ci\u003e横幹連合コンファレンス予稿集\u003c/i\u003e (No. 0; Vol. 2021). 特定非営利活動法人　横断型基幹科学技術研究団体連合. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.11487/oukan.2021.0_B-4-4\"\u003e10.11487/oukan.2021.0_B-4-4\u003c/a\u003e","url":"https://doi.org/10.11487/oukan.2021.0_B-4-4"}}}},"footer":{"navigation":{"prev":{"title":"Time series using STAC API statistics endpoints","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/igarss2022/igarss-22-timeseries-stac-api-single-vs-multi","group":"Contributions"},"next":{"title":"How to access IACS Spatial Data","url":"/external-notebooks/eurodatacube/notebooks/notebooks/curated/access-iacs-data","group":"Curated"}}},"domain":"http://localhost:3000"},"project":{"subject":"EarthCODE Examples","title":"EarthCODE Examples","description":"Collection of examples relevant to the EarthCODE project","github":"https://github.com/esa-earthcode/example-viewer/","id":"5aa0318b-5bc1-41e2-b1d4-053e8b61961b","exports":[],"bibliography":[],"index":"readme","pages":[{"title":"External Notebooks","level":1},{"title":"Eoxhub Workspaces","level":2},{"title":"Eoxhub Notebooks","level":3},{"title":"Dask Tutorials","level":4},{"slug":"external-notebooks.eoxhub-workspaces.eoxhub-notebooks.dask-tutorials.pangeo-example-wildfires","title":"Scale your processes with Dask - hands on example","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":5},{"title":"Eurodatacube","level":2},{"title":"Notebooks","level":3},{"slug":"external-notebooks.eurodatacube.notebooks.readme","title":"Jupyter notebooks","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":4},{"title":"Notebooks","level":4},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.readme","title":"Euro Data Cube Notebooks","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":5},{"title":"Contributions","level":5},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-ai4arctic-sea-ice","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-biomass-forest-observation-sys","title":"AIREO pilot dataset - Biomass (Forest Observation System)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-cap","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aireo-pilot-dataset-spacenet7","title":"Introduction","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.aot-covid19","title":"Aerosol Optical Thickness (AOT) Anomaly Detection Using Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.batch-zarr-output","title":"Generating Zarr data cubes with Sentinel Hub Batch API","description":"","date":"","thumbnail":"/example-viewer/build/68dffbf744fa42f4bf3d35e55684984e.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.client-side-processing-using-mass-sh","title":"Important notes","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.cmems-data-download","title":"Cmems Data Download","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.detect-trucks-sentinel2","title":"Detect Trucks using Sentinel-2 data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.drought-monitoring","title":"Drought impact monitoring platform","description":"","date":"","thumbnail":"/example-viewer/build/ad5c19782b006f72352ae57794305840.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-africa-cube-africa-custom-contest","title":"Custom Script Contest – Urban Growth in Africa","description":"","date":"","thumbnail":"/example-viewer/build/undefined","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-byoc-tutorial","title":"How to bring your own data to EDC: Using Sentinel Hub Python package","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-demo-phi-week-v2","title":"xcube-gen and xcube-geodb Hands-On Workshop Φ-Week 2020","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-geodb-4-eurocrops-demo","title":"Demonstration of Eurocrops data use in geoDB","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-notebook-lstm","title":"South Africa Crop Type Classification on Euro Data Cube (EDC)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-usecase-lpis-crop-type-classification","title":"Important notes","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.eurocrops-crop-classification-example","title":"Crop-classification using Sentinel-2 time-series","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.ghsl-urban-delineation","title":"\u003cb\u003eUrban delineation\u003cb\u003e","description":"","date":"","thumbnail":"/example-viewer/build/7bbf545a5eae1d9ebdb91ae42b261063.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.globalearthmonitor-example","title":"Pre-requisites","description":"","date":"","thumbnail":"/example-viewer/build/205c1ded6bd59771975a9fbd3753fd3b.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.gpu-support-eoxhub","title":"GPU-Support on EOxHub","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.gran-chaco-phiweek","title":"ESA EO \\phi- week 2020","description":"","date":"","thumbnail":"/example-viewer/build/80cee7db6cdc7002ceedda5689f889fa.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.howtolulc-batch-updated-210621","title":"How To: Land-Use-Land-Cover Prediction for Slovenia - using the Batch Processing API","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.lpis-lulc-slo","title":"LPIS Use Case for Land Use / Land Cover Classification","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.lps2022-leverage-euro-data-cube-services","title":"Living Planet Symposium 2022 Training Session","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.no2-analysis-covid19-lockdowns","title":"Impact of Covid19 induced lockdown on NO2 levels","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.no2-so2-trend-veda-api-igarss-2023","title":"Using the NASA VEDA EOAPI","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.ogc-edc","title":"Important notes","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.openeo-client-demo","title":"openEO Client Demo","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.race-finishedgoodsinventory-inidcator","title":"Finished Goods Inventory indicator for RACE","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.third-party-planetscope","title":"Third Party Data Import - PlanetScope","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.xcube-access-datasets","title":"Using xcube to access non-commercial and commercial data sets","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.xcube-viewer-as-a-service-in-edc1","title":"Visualizing data with xcube viewer in EuroDataCube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-evaluation-workshop","title":"DAPA Evaluation Workshop: Introduction \u0026 Documentation","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-1-cube-sentinel-2","title":"DAPA Tutorial #1: Cube - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-2-area-sentinel-2","title":"DAPA Tutorial #2: Area - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-3-timeseries-sentinel-2","title":"DAPA Tutorial #3: Timeseries - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-4-value-sentinel-2","title":"DAPA Tutorial #4: Value - Sentinel-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.dapa.dapa-tutorial-5-dem","title":"DAPA Tutorial #5: DEM","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.fairicube.fairicube-data-access-demonstration","title":"EDC Sentinel Hub - data access using xcube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-australian-bushfires","title":"Australian Bushfires","description":"","date":"","thumbnail":"/example-viewer/build/ab194b4f8c40a2b9d64d8a85e37ce1fd.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":["IGARSS-22","EO Dashboard"],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-data-access","title":"Data Access","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-detect-trucks-sentinel2","title":"Truck Detection Exercise","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-lockdown-in-venice","title":"Environmental Impacts of Lockdown in Venice, Italy during 2020","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-nasa-api-lockdown-in-venice","title":"Lockdown in Venice","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-no2-timeseries-analysis","title":"NO2 timeseries analysis","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.igarss2022.igarss-22-timeseries-stac-api-single-vs-multi","title":"Time series using STAC API statistics endpoints","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.nightlights.night-lights-blending","title":"Monitoring socio-economic activities with nighttime light maps","description":"","date":"","thumbnail":"/example-viewer/build/fb2486d4e1708daa94616c6ae8fc4cc9.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"title":"Curated","level":5},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.access-iacs-data","title":"How to access IACS Spatial Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-access-cci-data","title":"Access CCI data with xcube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-first-steps","title":"First steps on the Euro Data Cube platform","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-1-manage-datasets-v11","title":"Manage Collections in your GeoDB","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-2-explore-datasets-2","title":"Exploring Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-3-share-datasets1","title":"Sharing Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-geodb-access-urban-atlas-data-v1","title":"[xcube-geodb] How to accesss EEA Urban Atlas Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-data-access","title":"EDC Sentinel Hub - data access using xcube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinelhub-datafusion-basic","title":"EDC Sentinel Hub: Data Fusion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinelhub-datafusion-ndvi","title":"EDC Sentinel Hub: Data Fusion","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-datasets","title":"EDC Sentinel Hub - using xcube to access different data sets in Sentinel Hub","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-setup","title":"Setup for EDC core API access using xcube client library","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-sentinel-hub-xcube-integration","title":"EDC Sentinel Hub - XCUBE integration","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.edc-usecase-ndvi-timeline","title":"NDVI timeline","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.eo-learn","title":"Using eo-learn in EDC: a starter’s guide.","description":"","date":"","thumbnail":"/example-viewer/build/5a1f8475f0c3652f4630d03d72891b98.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.esdl-edc-v0-2","title":"Earth System Data Lab Tutorial @ Euro Data Cube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.exploring-time-and-space-with-edc","title":"Exploring Time and Space: A guide to accessing, analysing and visualising data in the Euro Data Cube","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.how-to-access-dem-data-through-sentinel-hub-api","title":"How to access DEM data through Sentinel Hub API","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6},{"slug":"external-notebooks.eurodatacube.notebooks.notebooks.curated.sentinelhub-py","title":"Using Sentinel Hub Process API in EDC: a starter’s guide.","description":"","date":"","thumbnail":"/example-viewer/build/01e22903839391bc356ac886ec2b2fa7.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":6}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/example-viewer/build/manifest-B4831781.js";
import * as route0 from "/example-viewer/build/root-QGLRP2PL.js";
import * as route1 from "/example-viewer/build/routes/$-7JYT5576.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/example-viewer/build/entry.client-UNPC4GT3.js");</script></body></html>