{"version":1,"kind":"Notebook","sha256":"d1fa2460b6ed455ce85a223fe2f4026cb70dc901f361da7277123c2ee28613c8","slug":"external-notebooks.eurodatacube.notebooks.notebooks.contributions.edc-notebook-lstm","location":"/external_notebooks/eurodatacube/notebooks/notebooks/contributions/edc_notebook_lstm.ipynb","dependencies":[],"frontmatter":{"title":"South Africa Crop Type Classification on Euro Data Cube (EDC)","content_includes_title":false,"kernelspec":{"name":"conda-env-users-edcg-2023.10-01-py","display_name":"users-edcg-2023.10-01","language":"python"},"github":"https://github.com/eurodatacube/example-viewer","subject":"Euro Data Cube Examples","numbering":{"title":{"offset":5}},"edit_url":"https://github.com/eurodatacube/example-viewer/blob/main/external_notebooks/eurodatacube/notebooks/notebooks/contributions/edc_notebook_lstm.ipynb","exports":[{"format":"ipynb","filename":"edc_notebook_lstm.ipynb","url":"/example-viewer/build/edc_notebook_lstm-66a0de94ed02f5c75f1a9d9281880aa0.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This notebook shows the steps towards preparing data for training a supervised machine learning model on EDC. We will train the model based on the optical bands with 10 m resolution of Sentinel-2 imagery, i.e., the B2, B3, B4, and B8.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TIGLPHml6x"}],"key":"kfhadl0k2P"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"We will use the Long Short-Term Memory model (LSTM), a variation of a recurrent neural network (RNN), which learns the temporal context of a particular yearly time series of a crop.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"QdEdSAEg8k"}],"key":"b1LgIQsJr8"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"As for the ground truth, we will use the ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"F0armKFSxo"},{"type":"link","url":"https://collections.eurodatacube.com/south-africa-crops-competition/","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"South Africa Crop Type Competition","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"fv3PYHuszE"}],"urlSource":"https://collections.eurodatacube.com/south-africa-crops-competition/","key":"E1JUXORwSm"},{"type":"text","value":" collection, which is part of the EDC public collection and contains the field identification label representing the area of crop fields and the corresponding crop type collected via aerial and vehicle surveys.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"kTBWtbvVRx"}],"key":"kr6j7EkG7A"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"In this example notebook, the expected outcome is a muticlass classifier that identifies different crop types planted in the fields in South Africa.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"yAU4h2Xwpb"}],"key":"teccKaj83A"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"We will prepare the training data in the following steps:","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"AM7os1HHn5"}],"key":"t1C0uXhUcv"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":12,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Search for available ground truth labels","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"rQ3r9oSLK0"}],"key":"BNEqWXaKRn"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Download features and labels","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"Ptcvo32BXy"}],"key":"zS2kmNCm45"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Reshape data for model training","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"d1dRgmSc0v"}],"key":"G38g9eJlWp"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Normalize and undersample data","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"wnwVodjIxU"}],"key":"OxBgrnjuxO"},{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Train model","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"h3mUKiGCHl"}],"key":"izrVtb2XmA"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Run model on validation data","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"CzTHwLAfn9"}],"key":"cPkF1dLdrj"},{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Evaluate results","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"cjulmqPOAG"}],"key":"dHBnL2yPW8"}],"key":"h3fj7ZYOdP"}],"key":"NhdWGy1alk"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"%load_ext autoreload\n%autoreload 2","visibility":"show","key":"XD68b5pay3"},{"type":"output","id":"-Yog3Bpo_-WIv5I4Yd7_G","data":[],"visibility":"show","key":"Cs9uAQhpJx"}],"visibility":"show","key":"IEV0mQLfxy"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import sys\n\nprint(sys.version)\n\n# NOTE: all necessary packages are preinstalled in the EuroDataCube curated 'edcg-2023.10-01' conda kernel!","visibility":"show","key":"fHKpcLJkPn"},{"type":"output","id":"fw3zz4bQvuQ0kN5IKRrCS","data":[{"name":"stdout","output_type":"stream","text":"3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0]\n"}],"visibility":"show","key":"vB0WZJYAAs"}],"visibility":"show","key":"B5ew66ftMN"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"import datetime\nimport os\nimport pickle\nfrom collections import defaultdict\n\nimport contextily as cx\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport torch\nimport torch.nn.functional as F\nfrom eolearn.core import (\n    EOExecutor,\n    EOPatch,\n    EOTask,\n    EOWorkflow,\n    FeatureType,\n    OverwritePermission,\n    SaveTask,\n    linearly_connect_tasks,\n)\nfrom eolearn.features.extra.interpolation import LinearInterpolationTask\nfrom eolearn.io import SentinelHubEvalscriptTask, SentinelHubInputTask\nfrom matplotlib.colors import BoundaryNorm, ListedColormap\nfrom sentinelhub import (\n    CRS,\n    Band,\n    BBox,\n    DataCollection,\n    SentinelHubStatistical,\n    SentinelHubStatisticalDownloadClient,\n    SHConfig,\n    Unit,\n    UtmZoneSplitter,\n    bbox_to_dimensions,\n)\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm.auto import tqdm\n\nrng = np.random.default_rng(42)","visibility":"show","key":"JZMBBJFe0P"},{"type":"output","id":"mI_CKLa3GxbzxFinp0MTn","data":[],"visibility":"show","key":"B1iOLaRA02"}],"visibility":"show","key":"vrT3wveG5F"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"1. Search for available ground truth’s labels","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ESEAxlx8ye"}],"identifier":"id-1-search-for-available-ground-truths-labels","label":"1. Search for available ground truth’s labels","html_id":"id-1-search-for-available-ground-truths-labels","implicit":true,"key":"eK2wcIgozE"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"To start preparing a training dataset, we need to find the areas which contain ground truth available in the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"wKK4k5scUT"},{"type":"link","url":"https://collections.eurodatacube.com/south-africa-crops-competition/","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"South Africa Crop Type Competition","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"r2WSssuyH4"}],"urlSource":"https://collections.eurodatacube.com/south-africa-crops-competition/","key":"YGSAc8PNut"},{"type":"text","value":" data collection on EDC. We will use the geographical coverage and the temporal availability provided on the linked webpage above to make a Catalog API request.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"QTJZ2Dx8RK"}],"key":"dBziIXXqtq"}],"key":"NAfaDxagOE"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# load the SH config\nconfig = SHConfig()\n\n# split the AOI into 2560m x 2560m tiles\nextent = BBox((17.85, -33.089240, 18.193359, -32.7), crs=CRS.WGS84)\nbbox_list = UtmZoneSplitter([extent.geometry], crs=extent.crs, bbox_size=[2560, 2560]).bbox_list","visibility":"show","key":"wufT9TpFRC"},{"type":"output","id":"LQAQeZCA39R_X5G5lvmgb","data":[{"name":"stderr","output_type":"stream","text":"/home/conda/users/78c2e9a35d8f916b51e069b3359b976953e33c4ac102d2c530b5373dd8486c9d-20240215-082503-014013-382-edcg-2023.10-01/lib/python3.10/site-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n  return lib.intersection(a, b, **kwargs)\n/home/conda/users/78c2e9a35d8f916b51e069b3359b976953e33c4ac102d2c530b5373dd8486c9d-20240215-082503-014013-382-edcg-2023.10-01/lib/python3.10/site-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n  return lib.intersection(a, b, **kwargs)\n"}],"visibility":"show","key":"zLZbovQ9qb"}],"visibility":"show","key":"Wbt2rleL2d"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"plt.style.use([\"default\", \"bmh\"])\nfig, ax = plt.subplots(figsize=(12, 5))\nfig.patch.set_alpha(1)\n\n# construct grid for plotting\ngrid = defaultdict(list)\nfor idx, bbox in enumerate(bbox_list):\n    grid[bbox.crs.epsg].append({\"geometry\": bbox.geometry, \"bbox_id\": idx})\n\ngdf_list = [\n    gpd.GeoDataFrame(subset, geometry=\"geometry\", crs=crs).to_crs(CRS.WGS84.epsg) for crs, subset in grid.items()\n]\ngdf = pd.concat(gdf_list).sort_values(\"bbox_id\").reset_index(drop=True)\n\n# plot grid and basemap\ngdf.plot(edgecolor=\"k\", alpha=0.2, ax=ax)\ncx.add_basemap(ax, crs=gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)","visibility":"show","key":"j7TxGzcYjn"},{"type":"output","id":"LQMzyt91kDbIquC_Kg3eb","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"e33aa4016a1f9b7fc3affc4a543094a6","path":"/example-viewer/build/e33aa4016a1f9b7fc3affc4a543094a6.png"},"text/plain":{"content":"<Figure size 1200x500 with 1 Axes>","content_type":"text/plain"}}}],"visibility":"show","key":"xpJ1i6B3kE"}],"visibility":"show","key":"jMpRj7grhI"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def get_coverage_request(\n    bbox: BBox,\n    time_interval: tuple[str, str],\n    evalscript: str,\n    collection: DataCollection = DataCollection.SENTINEL2_L2A,\n):\n    \"\"\"Construct request for SentinelHubStatistical data to get coverage of labels in the tile\"\"\"\n    patch_size = bbox_to_dimensions(bbox, resolution=60)\n\n    return SentinelHubStatistical(\n        aggregation=SentinelHubStatistical.aggregation(\n            evalscript=evalscript,\n            time_interval=time_interval,\n            aggregation_interval=\"P1D\",\n            size=patch_size,\n        ),\n        input_data=[SentinelHubStatistical.input_data(collection)],\n        bbox=bbox,\n    )\n\n\n# prepare evalscript for downloading crop labels\nlabels_evalscript = \"\"\"\n//VERSION=3\n\nfunction setup() {\n    return {\n        input: [\n            {\"bands\": [\"crop\", \"dataMask\"]}\n        ],\n        output: [\n            {\n                id: \"LABELS\",\n                bands: 1,\n                sampleType: \"UINT8\"\n            },\n            {\n                id: \"dataMask\",\n                bands: 1,\n                sampleType: \"UINT8\"\n            }\n        ]\n    };\n}\n\nfunction evaluatePixel(sample) {\n    return {LABELS: [sample.crop], dataMask: [sample.dataMask]};\n}\n\"\"\"\n\n# define collection which points to crop labels\ncollection_id = \"bd457670-af1b-45cd-bef2-6a7c93bf5e6e\"\nsouth_africa_crop = DataCollection.define_byoc(\n    collection_id, bands=[Band(name=\"crop\", units=(Unit.DN,), output_types=(np.uint8,))], metabands=[], is_timeless=True\n)\n\n# specify labels definition time (from webpage) and run the requests\nlabels_time_interval = (\"2017-08-01\", \"2017-08-02\")\nkwargs = dict(time_interval=labels_time_interval, evalscript=labels_evalscript, collection=south_africa_crop)\nrequests = [get_coverage_request(bbox, **kwargs).download_list[0] for bbox in bbox_list]\nclient = SentinelHubStatisticalDownloadClient()\n\n# download or load data from disk\nif not os.path.exists(\"stats.pkl\"):\n    stats = client.download(requests)\n    pickle.dump(stats, open(\"stats.pkl\", \"wb\"))\nelse:\n    stats = pickle.load(open(\"stats.pkl\", \"rb\"))","visibility":"show","key":"Fmotzu3llZ"},{"type":"output","id":"FEeIauXSMZ700dUVQiCXV","data":[],"visibility":"show","key":"hPFBZmXNzI"}],"visibility":"show","key":"HKV1rbWhJy"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"def extract_coverage(stats: list[dict]):\n    \"\"\"Extract labels coverage from the statistical data\"\"\"\n    data = stats[\"data\"][0][\"outputs\"][\"LABELS\"][\"bands\"][\"B0\"][\"stats\"]\n    return 1 - data[\"noDataCount\"] / data[\"sampleCount\"]\n\n\n# extract coverage from the stats\ncoverages = np.array([extract_coverage(s) if s[\"data\"] else 0 for s in stats])","visibility":"show","key":"Io16rCFWdg"},{"type":"output","id":"ypeNmAbZGp0Xq9xz0eExB","data":[],"visibility":"show","key":"grG0IptW7n"}],"visibility":"show","key":"vAdc1ZcEFA"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"plt.style.use([\"default\", \"bmh\"])\nfig, ax = plt.subplots(figsize=(15, 5))\nfig.patch.set_alpha(1)\n\n# plot labels coverage over tiles, ignore tiles with no data\nax.hist(coverages[coverages > 0], bins=30)\nax.set_xlabel(\"Reference data coverage\");","visibility":"show","key":"MhUJi5Ebrc"},{"type":"output","id":"S3XtBNUnDL5oK4gxHu_YM","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"9ca6b536533a2d663a7a1012cdad50b0","path":"/example-viewer/build/9ca6b536533a2d663a7a1012cdad50b0.png"},"text/plain":{"content":"<Figure size 1500x500 with 1 Axes>","content_type":"text/plain"}}}],"visibility":"show","key":"CbwNuAQOzx"}],"visibility":"show","key":"vI9F1BV2vi"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"","key":"tpMInFY4LZ"},{"type":"output","id":"l2uI8p4KTBSJVbKSRh8Go","data":[],"key":"Igj3wYnmAL"}],"key":"PcR58PJ3hK"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# let's keep only the tiles with coverage above 40%\ncoverage_filter = np.array(coverages) > 0.40\nprint(f\"{np.count_nonzero(coverage_filter)} eligible patches\")\n\nfiltered = np.array(bbox_list)[coverage_filter]","visibility":"show","key":"zpw0ME7ctA"},{"type":"output","id":"raEofVD_cPr4TY2Ai8ysl","data":[{"name":"stdout","output_type":"stream","text":"63 eligible patches\n"}],"visibility":"show","key":"ZiZUrfkXaK"}],"visibility":"show","key":"UpriPjt88d"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"plt.style.use([\"default\", \"bmh\"])\nfig, ax = plt.subplots(figsize=(12, 5))\nfig.patch.set_alpha(1)\n\n# set new column\ngdf[\"eligible\"] = coverage_filter\n\n# plot grid and basemap\ngdf.plot(color=\"none\", edgecolor=\"k\", alpha=0.2, ax=ax)\ngdf[gdf[\"eligible\"]].plot(color=\"C0\", edgecolor=\"k\", alpha=0.5, ax=ax)\ncx.add_basemap(ax, crs=gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)","visibility":"show","key":"Rxn8o6nvap"},{"type":"output","id":"6DP0zibHXJ3sUiJefseLH","data":[{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"692056e1100b97481d8ae22cda7d69a3","path":"/example-viewer/build/692056e1100b97481d8ae22cda7d69a3.png"},"text/plain":{"content":"<Figure size 1200x500 with 1 Axes>","content_type":"text/plain"}}}],"visibility":"show","key":"wfskZTQZe7"}],"visibility":"show","key":"g3tyDoQxaG"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"2. Download features and labels","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bhCLK25SpS"}],"identifier":"id-2-download-features-and-labels","label":"2. Download features and labels","html_id":"id-2-download-features-and-labels","implicit":true,"key":"t9pQzphBIm"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Now we know where the groud truth is available, we use eo-learn to download the data and the labels. This is what the eo-learn workflow does:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AbzKiTBxK2"}],"key":"fui0aDFhHp"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":4,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"Download bands data (B, G, R, NIR)","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"tdAP7JRA1w"}],"key":"iGlHchzOIM"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Download labels data","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"IECgZjKh08"}],"key":"c7WARGfTei"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Construct valid mask from data availability mask and cloud mask","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"uhl1Lyv1Aq"}],"key":"OfNA9UeHC7"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Perform temporal interpolation and resample to uniform timestamps across whole AOI","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"RS4Dx8tGzu"}],"key":"xm4DaY9uq3"}],"key":"rpBHo3dMYW"}],"key":"yUG6OMRPmh"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"For the purpose of this notebook, we will download only 2 EOPatches, but to properly train the model, set the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oen9T9kO43"},{"type":"inlineCode","value":"tutorial_mode","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JDBgd6eyYN"},{"type":"text","value":" to ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OVCiYUMOdl"},{"type":"inlineCode","value":"False","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uEapXNdX6u"},{"type":"text","value":" to properly train the model","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BP73rq8KDl"}],"key":"ORbPZo9RIk"}],"key":"Za8ixCNvzJ"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"tutorial_mode = True\nif tutorial_mode:  # select first two eligible EOPatches\n    subset = [18, 20]\n    selected = filtered[subset]\n    gdf[\"selected\"] = False\n    gdf.loc[gdf.loc[gdf.eligible].index[subset], \"selected\"] = True\nelse:  # select all eligible EOPatches\n    selected = filtered\n    gdf[\"selected\"] = coverage_filter","visibility":"show","key":"ucu2yR5vjU"},{"type":"output","id":"qN50fH_ip69z4wpeseLXI","data":[],"visibility":"show","key":"iLkUYdA6zx"}],"visibility":"show","key":"GYYSGh94E5"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# prepare task for joining valid data mask and cloud masks from SH\nclass SentinelHubValidDataTask(EOTask):\n    \"\"\"\n    Combine the downloaded cloud mask with `IS_DATA` to define a valid data mask\n    The SentinelHub's cloud mask is expected in eopatch.mask['CLM']\n    \"\"\"\n\n    def __init__(self, output_feature):\n        self.output_feature = output_feature\n\n    def execute(self, eopatch):\n        eopatch[self.output_feature] = eopatch.mask[\"IS_DATA\"].astype(bool) & (~eopatch.mask[\"CLM\"].astype(bool))\n        return eopatch\n\n\n# BAND DATA\n# Add a request for S2 bands.\n# Here we also do a simple filter of cloudy scenes (on tile level).\n# The s2cloudless masks are requested via additional data.\nband_names = [\"B02\", \"B03\", \"B04\", \"B08\"]\nadd_data = SentinelHubInputTask(\n    bands_feature=(FeatureType.DATA, \"BANDS\"),\n    bands=band_names,\n    resolution=10,\n    maxcc=0.8,\n    time_difference=datetime.timedelta(minutes=120),\n    data_collection=DataCollection.SENTINEL2_L2A,\n    additional_data=[(FeatureType.MASK, \"dataMask\", \"IS_DATA\"), (FeatureType.MASK, \"CLM\")],\n    max_threads=5,\n)\n\n# LABELS DATA\n# Add a request for crop labels.\nadd_labels = SentinelHubEvalscriptTask(\n    features=(FeatureType.MASK_TIMELESS, \"LABELS\"),\n    evalscript=labels_evalscript,\n    data_collection=south_africa_crop,\n    resolution=10,\n    max_threads=5,\n)\n\n# VALIDITY MASK\n# Validate pixels using SentinelHub's cloud detection mask and region of acquisition\nadd_sh_validmask = SentinelHubValidDataTask((FeatureType.MASK, \"IS_VALID\"))\n\n# LINEAR TEMPORAL INTERPOLATION\n# linear interpolation of full time-series and date resampling\n# needed to evaluate time series at specific dates for all data\ntime_interval = (\"2017-01-01\", \"2017-12-31\")\nresampled_range = (time_interval[0], time_interval[1], 15)  # define target timestamps (every 15 days)\nlinear_interp = LinearInterpolationTask(\n    (FeatureType.DATA, \"BANDS\"),  # name of field to interpolate\n    mask_feature=(FeatureType.MASK, \"IS_VALID\"),  # mask to be used in interpolation\n    copy_features=[(FeatureType.MASK_TIMELESS, \"LABELS\")],  # features to keep\n    resample_range=resampled_range,\n)\n\n# SAVING TO OUTPUT\nsave = SaveTask(\"./eopatches\", overwrite_permission=OverwritePermission.OVERWRITE_FEATURES)","visibility":"show","key":"jZ5S58qTzy"},{"type":"output","id":"9tqRdnGniBADuJNAgaVQO","data":[],"visibility":"show","key":"HlvMDNWB7s"}],"visibility":"show","key":"aQHNtLK8xy"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# Define the workflow\nworkflow_nodes = linearly_connect_tasks(\n    add_data,\n    add_labels,\n    add_sh_validmask,\n    linear_interp,\n    save,\n)\nworkflow = EOWorkflow(workflow_nodes)\n\n# Define additional parameters of the workflow\ninput_bands = workflow_nodes[0]\nsave_node = workflow_nodes[-1]\nexecution_args = []\nfor idx, bbox in enumerate(selected):\n    execution_args.append(\n        {\n            input_bands: {\"bbox\": bbox, \"time_interval\": time_interval},\n            save_node: {\"eopatch_folder\": f\"eopatch_{idx}\"},\n        }\n    )\n\n# Execute the workflow\nif not os.path.exists(\"eopatches\"):\n    executor = EOExecutor(workflow, execution_args, save_logs=True)\n    executor.run(workers=2)","visibility":"show","key":"qTtdDzjGIH"},{"type":"output","id":"fTJdxINt-0Fu_a7P4zyoZ","data":[{"output_type":"display_data","metadata":{},"data":{"application/vnd.jupyter.widget-view+json":{"content":"{\"model_id\":\"5224204b0f364154932cacb96d19746f\",\"version_major\":2,\"version_minor\":0}","content_type":"application/vnd.jupyter.widget-view+json"},"text/plain":{"content":"  0%|          | 0/2 [00:00<?, ?it/s]","content_type":"text/plain"}}}],"visibility":"show","key":"LlkBNq7O5w"}],"visibility":"show","key":"u9fpBX5Z6f"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"# collect the data and labels over all eopatches\ndata_list = []\nlabels_list = []\nfor eop_idx in tqdm(range(len(selected))):\n    eop = EOPatch.load(f\"./eopatches/eopatch_{eop_idx}\")\n    data_list.append(eop.data[\"BANDS\"])\n    labels_list.append(eop.mask_timeless[\"LABELS\"])","visibility":"show","key":"Z6hlEylxmS"},{"type":"output","id":"WOdFM6Vk7s3wXdRRwA8oA","data":[],"visibility":"show","key":"pnqtBAcS37"}],"visibility":"show","key":"ZpwZQRE1fG"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# plot selected scenes in true color\nncols = 2\nnrows = 1\ntime_idx = 12\n\nplt.style.use([\"default\", \"bmh\"])\nfig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols * 2, nrows * 2))\nfig.patch.set_alpha(1)\n\nfor ax, image in zip(axs.flatten(), data_list):\n    ax.imshow(np.clip(image[time_idx][..., [2, 1, 0]] * 3.5, 0, 1))\n    ax.axis(\"off\")\n\nplt.tight_layout()","key":"vmKPZN41D1"},{"type":"output","id":"jmMhk9_K3_dZJ6dlCeeX1","data":[],"key":"HOWH964BOu"}],"key":"K7W9vPapH2"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# plot also labels\nncols = 2\nnrows = 1\n\nlabel_codes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nlabel_colors = [\n    \"#ffffff\",\n    \"#a6cee3\",\n    \"#1f78b4\",\n    \"#b2df8a\",\n    \"#33a02c\",\n    \"#fb9a99\",\n    \"#e31a1c\",\n    \"#fdbf6f\",\n    \"#ff7f00\",\n    \"#cab2d6\",\n]\nlabel_text = [\n    \"No data\",\n    \"Lucerne/Medics\",\n    \"Planted pastures (perennial)\",\n    \"Fallow\",\n    \"Wine grapes\",\n    \"Weeds\",\n    \"Small grain grazing\",\n    \"Wheat\",\n    \"Canola\",\n    \"Rooibos\",\n]\n\nplt.style.use([\"default\", \"bmh\"])\nfig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols * 2, nrows * 2))\nfig.patch.set_alpha(1)\n\ncmap = ListedColormap(label_colors)\nnorm = BoundaryNorm(label_codes, 10)\n\nfor ax, image in zip(axs.flatten(), labels_list):\n    ax.imshow(image.squeeze(-1), cmap=cmap, norm=norm, interpolation=\"none\")\n    ax.axis(\"off\")\n\nplt.tight_layout()","key":"YGhEqbmm6R"},{"type":"output","id":"s21wI-H8Zw_w5al5CUnGk","data":[],"key":"rR3Xl8n0uk"}],"key":"HoxAmJK2KE"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"3. Reshape data for model training","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PbrbxDLPNz"}],"identifier":"id-3-reshape-data-for-model-training","label":"3. Reshape data for model training","html_id":"id-3-reshape-data-for-model-training","implicit":true,"key":"xFBvGYMp0L"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The data for the LSTM model needs to be in the form of ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"XfZnPmBgy4"},{"type":"inlineCode","value":"N x T x C","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"nnjWzhQT1F"},{"type":"text","value":", where ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ySVMX0tkbt"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"N","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"zpUwK3ea04"}],"key":"y4hmyUIIX1"},{"type":"text","value":" represents the number of pixels, ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AQwoh5aXAD"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"T","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gY6XPDcaRQ"}],"key":"XfA08patyO"},{"type":"text","value":" represents the number of timestamps, and ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Lw5MWaeKtk"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"C","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"f9F4WrLKOm"}],"key":"CWQwDyJeYo"},{"type":"text","value":" the number of channels.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"zccFtP2OxG"}],"key":"XptHzUlKdK"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"We have 25 timestamps and 4 channels (B, G, R, NIR).","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"sS8692hdFG"}],"key":"KXrPeJ2iKw"}],"key":"lz9Mex53b5"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# split tiles into train and validation patches\ntrain_slice = slice(None, None, 2)  # evens\nval_slice = slice(1, None, 2)  # odds\n\ntrain_data, train_labels = data_list[train_slice], labels_list[train_slice]\nvalidate_data, validate_labels = data_list[val_slice], labels_list[val_slice]\n\nsel_gdf = gdf[gdf.selected].copy()\nsel_gdf[\"train_split\"] = False\nsel_gdf.loc[train_slice, \"train_split\"] = True\n\nplt.style.use([\"default\", \"bmh\"])\nfig, ax = plt.subplots(figsize=(12, 5))\nfig.patch.set_alpha(1)\n\n# plot grid and basemap\ngdf.plot(color=\"none\", edgecolor=\"k\", alpha=0.2, ax=ax)\nsel_gdf[sel_gdf.train_split].plot(color=\"xkcd:green\", edgecolor=\"k\", alpha=0.2, ax=ax)\nsel_gdf[~sel_gdf.train_split].plot(color=\"xkcd:brick\", edgecolor=\"k\", alpha=0.2, ax=ax)\ncx.add_basemap(ax, crs=gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)","key":"KGlppYaPbd"},{"type":"output","id":"nJcTl5ClI1z621lKXGYYT","data":[],"key":"MoSmb0VVJj"}],"key":"bBP3ZMxJTu"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# function for extracting and reshaping the data and labels\ndef get_model_input(data: np.ndarray, labels: np.ndarray) -> tuple:\n    t, h, w, d = data.shape\n    x = np.reshape(np.moveaxis(data, 0, -2), (h * w, t, d))  # N x T x C\n    y = np.reshape(labels, (h * w))\n    return x[y != 0], y[y != 0]","key":"gMSqmM300f"},{"type":"output","id":"1rI8n7oXE_Rg8CAWZxtl6","data":[],"key":"xTiReAVmMb"}],"key":"qx4pdxgEWp"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# reshape for train data\nx_train, y_train = [], []\nfor data, labels in zip(train_data, train_labels):\n    model_input = get_model_input(data, labels)\n    x_train.append(model_input[0])\n    y_train.append(model_input[1])\n\nx_train = np.concatenate(x_train, axis=0).astype(np.float32)\ny_train = np.concatenate(y_train, axis=0).astype(np.uint8)\ndel train_data, train_labels\n\nprint(x_train.shape)\nprint(y_train.shape)","key":"KG4GlBltkA"},{"type":"output","id":"MkT6szn5qpUvBYhVJQq-1","data":[],"key":"I4BY14RqT5"}],"key":"ErgZzbV7x5"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# reshape for validation data\nx_validate, y_validate = [], []\nfor data, labels in zip(validate_data, validate_labels):\n    model_input = get_model_input(data, labels)\n    x_validate.append(model_input[0])\n    y_validate.append(model_input[1])\n\nx_validate = np.concatenate(x_validate, axis=0).astype(np.float32)\ny_validate = np.concatenate(y_validate, axis=0).astype(np.uint8)\ndel validate_data, validate_labels\n\nprint(x_validate.shape)\nprint(y_validate.shape)","key":"StVd402Lr2"},{"type":"output","id":"XYpNxE_J7R_MykOkt5KPR","data":[],"key":"pCyCJRAV9C"}],"key":"KP56nTaCLQ"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"plt.style.use([\"default\", \"bmh\"])\nfig, ax = plt.subplots(figsize=(15, 5), ncols=2, sharex=True)\nfig.patch.set_alpha(1)\n\nlabels_dict = dict(zip(label_codes, label_text))\n\nlabels, counts = np.unique(y_train, return_counts=True)\nax[0].barh(range(len(labels)), counts)\nax[0].set_title(\"Train data labels distribution\")\nax[0].set_yticks(range(len(labels)), [labels_dict[lbl] for lbl in labels])\n\nlabels, counts = np.unique(y_validate, return_counts=True)\nax[1].barh(range(len(labels)), counts)\nax[1].set_title(\"Validation data labels distribution\")\nax[1].set_yticks(range(len(labels)), [labels_dict[lbl] for lbl in labels])\n\nplt.tight_layout()","key":"qJUo4kPjTy"},{"type":"output","id":"UkmDOoROQVb1SHpNdVl8x","data":[],"key":"lLDYfjGohR"}],"key":"UYZRrunxtI"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"4. Normalize and undersample data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"li3ZFEelzg"}],"identifier":"id-4-normalize-and-undersample-data","label":"4. Normalize and undersample data","html_id":"id-4-normalize-and-undersample-data","implicit":true,"key":"DbgDX6ZN4Q"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"For the columns that contain numerical data, we should ensure the data range is normalized in case the data has different scales. This process may improve the models performance, and also preserve outliers.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"wwZWLn5uWW"}],"key":"VQXbHEghKl"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Here we will use a simple method of undersampling just to minimize the amount of huge data we are handling, but the balance of the classes will remain the same.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"FiF4jfd4ec"}],"key":"enTTgLirPE"}],"key":"l6pIqzIwtK"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# set random seet\nnp.random.seed(42)\n\n# define percentage of data to use\npercentage = 0.3\n\n# sample train data\nsample_mask = np.random.choice(x_train.shape[0], int(percentage * x_train.shape[0]))\nclass_counts_before = np.unique(y_train, return_counts=True)\nx_train = x_train[np.sort(sample_mask)]\ny_train = y_train[np.sort(sample_mask)]\nclass_counts_after = np.unique(y_train, return_counts=True)\n\n# sample validation data\nsample_mask_val = np.random.choice(x_validate.shape[0], int(percentage * x_validate.shape[0]))\nx_validate = x_validate[sample_mask_val]\ny_validate = y_validate[sample_mask_val]\n\n# normalize train data\nn, t, c = x_train.shape\nx_train = StandardScaler().fit_transform(x_train.reshape(n * t, c)).reshape(n, t, c)\n\n# normalize validation data\nn, t, c = x_validate.shape\nval_scaler = StandardScaler().fit(x_validate.reshape(n * t, c))\nx_validate = val_scaler.transform(x_validate.reshape(n * t, c)).reshape(n, t, c)\n\n# check shapes\nx_train.shape, x_validate.shape","key":"uv4eRdniZ2"},{"type":"output","id":"EC-v3N7hcFmt5WDBksxQq","data":[],"key":"K4PbudyGpF"}],"key":"DH1sa2QuPS"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# fill nan values with -1\nx_train = np.nan_to_num(x_train, nan=-1)\nx_validate = np.nan_to_num(x_validate, nan=-1)","key":"wgFdnffJw6"},{"type":"output","id":"ktrGglKyFoy0aki9ctP21","data":[],"key":"uKcct7oxvC"}],"key":"Ma5CjjoamX"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# check labels distribution before and after undersampling\nplt.style.use([\"default\", \"bmh\"])\nfig, axs = plt.subplots(figsize=(12, 7), ncols=2)\nfig.patch.set_alpha(1)\n\nlabels_dict = dict(zip(label_codes, label_text))\ncolors_dict = dict(zip(label_codes, label_colors))\n\naxs[0].pie(\n    class_counts_before[1],\n    labels=[labels_dict[lbl] for lbl in class_counts_before[0]],\n    autopct=\"%1.1f%%\",\n    colors=[colors_dict[lbl] for lbl in class_counts_before[0]],\n    wedgeprops={\"linewidth\": 2, \"edgecolor\": \"white\", \"alpha\": 0.7},\n)\naxs[0].set_title(\"Class Distribution Before Undersampling\")\n\naxs[1].pie(\n    class_counts_after[1],\n    labels=[labels_dict[lbl] for lbl in class_counts_after[0]],\n    autopct=\"%1.1f%%\",\n    colors=[colors_dict[lbl] for lbl in class_counts_after[0]],\n    wedgeprops={\"linewidth\": 2, \"edgecolor\": \"white\", \"alpha\": 0.7},\n)\naxs[1].set_title(\"Class Distribution After Undersampling\")\n\nplt.tight_layout()","key":"evgcimUPrN"},{"type":"output","id":"bw_9WGHTm0Mkq_NCmDL7z","data":[],"key":"UNoifOsx0k"}],"key":"FPTewE2t31"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"5. Train the model","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"D6zfI8KrUP"}],"identifier":"id-5-train-the-model","label":"5. Train the model","html_id":"id-5-train-the-model","implicit":true,"key":"AN1WKiAFfn"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Now it’s time to construct and train the LSTM model. First we need a bunch of classes that the model will use, from the dataloaders to the model itself.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"XQA7qyUrDO"}],"key":"l6N33XXkGs"}],"key":"TC7xGSJ6OX"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Define the data loaders","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WMjfJ4dH8U"}],"identifier":"define-the-data-loaders","label":"Define the data loaders","html_id":"define-the-data-loaders","implicit":true,"key":"EZb0yfiiwh"}],"key":"jBP0TPFkO4"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# class for the dataloader\nclass CustomImageDataset(Dataset):\n    def __init__(self, x_data: np.ndarray, y_data: np.ndarray, encoder: LabelEncoder):\n        self.x_data = x_data\n        self.y_data = encoder.transform(y_data)\n\n    def __len__(self):\n        return len(self.y_data)\n\n    def __getitem__(self, idx):\n        return self.x_data[idx], self.y_data[idx]\n\n\n# encode labels to 0 - num_labels\nencoder = LabelEncoder().fit(list(set(y_train) | set(y_validate)))\nfor lbl in encoder.classes_:\n    print(f\"{lbl} -> {encoder.transform([lbl])[0]}\")","key":"zxo0kDaFFa"},{"type":"output","id":"e83HxQeEHvQSLtU2v5Uod","data":[],"key":"bmaGcS41ZU"}],"key":"dNAGophfhU"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# define the batch size and the dataloaders for train/validation data\nBATCH_SIZE = 1024 if tutorial_mode else 4096\ntrain_dataloader = DataLoader(CustomImageDataset(x_train, y_train, encoder), batch_size=BATCH_SIZE, shuffle=True)\nvalidation_dataloader = DataLoader(\n    CustomImageDataset(x_validate, y_validate, encoder), batch_size=BATCH_SIZE, shuffle=True\n)","key":"HakMdJ8mUQ"},{"type":"output","id":"vpd0v7FX5awy0In8xLBVy","data":[],"key":"TgxZQOJYxs"}],"key":"yfIwpdeqbX"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Define the model architecture","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"U9hb5GEN5p"}],"identifier":"define-the-model-architecture","label":"Define the model architecture","html_id":"define-the-model-architecture","implicit":true,"key":"mIXVPjIyOl"}],"key":"DbyHhBwFBe"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"class AverageMetric:\n    \"\"\"\n    Simple class for averaging metrics.\n    \"\"\"\n\n    def __init__(self):\n        self.values = list()\n\n    def add(self, new):\n        self.values.append(new)\n\n    def get(self):\n        return np.array(self.values).mean()\n\n\n# This code is taken from https://github.com/TUM-LMF/BreizhCrops\nclass LSTM(nn.Module):\n    \"\"\"\n    Implementation of the LSTM model for classification of a input sequence into n classes.\n\n    :param input_dim: number of input features entering LSTM cell (i.e. 13 if all S2 bands are used)\n    :type input_dim: int\n    :param n_classes: number of classes\n    :type n_classes: int (class labels have to be between 0 and n_classes-1)\n    :param hidden_dims: The number of features in the hidden state `h`\n    :type hidden_dims: int\n    :param num_rnn_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n                           would mean stacking two LSTMs together to form a `stacked LSTM`,\n                           with the second LSTM taking in outputs of the first LSTM and\n                           computing the final results.\n    :type num_rnn_layers: int\n    :param dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n                    LSTM layer except the last layer, with dropout probability equal to\n                    :attr:`dropout`.\n    :type dropout: float (between 0.0 and 1.0)\n    :param bidirectional: If ``True``, becomes a bidirectional LSTM.\n    :type bidirectional: bool\n    :param use_batchnorm: If ``True``, use batch normalization.\n    :type use_batchnorm: bool\n    :param use_layernorm: If ``True``, applies Layer Normalization over a mini-batch of inputs.\n    :type use_layernorm: bool\n    \"\"\"\n\n    def __init__(\n        self,\n        input_dim,\n        n_classes,\n        hidden_dims,\n        num_rnn_layers=1,\n        dropout=0,\n        bidirectional=False,\n        use_batchnorm=False,\n        use_layernorm=True,\n    ):\n        super().__init__()\n\n        self.nclasses = n_classes\n        self.use_batchnorm = use_batchnorm\n        self.use_layernorm = use_layernorm\n\n        self.d_model = num_rnn_layers * hidden_dims\n        if use_layernorm:\n            self.inlayernorm = nn.LayerNorm(input_dim)\n            self.clayernorm = nn.LayerNorm((hidden_dims + hidden_dims * bidirectional) * num_rnn_layers)\n\n        self.lstm = nn.LSTM(\n            input_size=input_dim,\n            hidden_size=hidden_dims,\n            num_layers=num_rnn_layers,\n            bias=False,\n            batch_first=True,\n            dropout=dropout,\n            bidirectional=bidirectional,\n        )\n\n        if bidirectional:\n            hidden_dims = hidden_dims * 2\n\n        self.linear_class = nn.Linear(hidden_dims * num_rnn_layers, n_classes, bias=True)\n\n        if use_batchnorm:\n            self.bn = nn.BatchNorm1d(hidden_dims)\n\n    def _logits(self, x):\n        x = x.transpose(1, 2)\n\n        if self.use_layernorm:\n            x = self.inlayernorm(x)\n\n        outputs, last_state_list = self.lstm.forward(x)\n\n        # TODO: check what is goinig on here\n        if self.use_batchnorm:\n            b, t, d = outputs.shape\n            o_ = outputs.view(b, -1, d).permute(0, 2, 1)\n            outputs = self.bn(o_).permute(0, 2, 1).view(b, t, d)\n\n        h, c = last_state_list\n\n        nlayers, batchsize, n_hidden = c.shape\n        # TODO: shouldn't this be executed only uf layernorm is True\n        h = self.clayernorm(c.transpose(0, 1).contiguous().view(batchsize, nlayers * n_hidden))\n        logits = self.linear_class.forward(h)\n\n        return logits\n\n    def forward(self, x):\n        logits = self._logits(x)\n        logprobabilities = F.log_softmax(logits, dim=-1)\n        return logprobabilities\n\n    def save(self, path=\"model.pth\", **kwargs):\n        model_state = self.state_dict()\n        os.makedirs(os.path.dirname(path), exist_ok=True)\n        torch.save(dict(model_state=model_state, **kwargs), path)\n\n    def load(self, path):\n        snapshot = torch.load(path, map_location=\"cpu\")\n        model_state = snapshot.pop(\"model_state\", snapshot)\n        self.load_state_dict(model_state)\n        return snapshot\n\n    def update_and_freeze_body(self, pretrained, freeze_layers=(0, -1)):\n        self.inlayernorm = pretrained.inlayernorm\n        self.clayernorm = pretrained.clayernorm\n        self.lstm = pretrained.lstm\n\n        for child in list(self.children())[freeze_layers[0] : freeze_layers[1]]:\n            for param in child.parameters():\n                param.requires_grad = False\n\n    def unfreeze(self):\n        for child in self.children():\n            for param in child.parameters():\n                param.requires_grad = True\n\n\ndef train(model, optimizer, train_loader, validation_loader, epochs):\n    \"\"\"\n    Vanilla function to run the inference on all train samples given in training dataloader.\n    At each epoch end the loss and accuracy of samples from the validation loader are printed.\n    \"\"\"\n    model.train()\n\n    if torch.cuda.is_available():\n        model = model.cuda()\n\n    for epoch in range(epochs):\n        # train phase\n        train_loss_log = AverageMetric()\n        model.train()\n        for data in train_loader:\n            optimizer.zero_grad()\n\n            inputs, targets = data\n\n            if torch.cuda.is_available():\n                inputs = inputs.cuda()\n                targets = targets.cuda()\n\n            logprobabilities = model.forward(inputs.transpose(1, 2))\n\n            loss = torch.nn.functional.nll_loss(logprobabilities, targets)\n            train_loss_log.add(loss.cpu().detach().numpy())\n\n            loss.backward()\n            optimizer.step()\n\n        # val phase\n        val_loss_log = AverageMetric()\n        model.eval()\n        predictions_list = list()\n        targets_list = list()\n        for _, data in enumerate(validation_loader):\n            inputs, targets = data\n\n            if torch.cuda.is_available():\n                inputs = inputs.cuda()\n                targets = targets.cuda()\n\n            logprobabilities = model.forward(inputs.transpose(1, 2))\n            loss = torch.nn.functional.nll_loss(logprobabilities, targets)\n            val_loss_log.add(loss.cpu().detach().numpy())\n\n            targets_list.append(targets.cpu().detach().numpy())\n            predictions_list.append((logprobabilities.cpu().detach().numpy()).argmax(1))\n\n        val_acc = accuracy_score(np.concatenate(targets_list), np.concatenate(predictions_list))\n        print(\n            f\"Epoch {epoch}: train loss {train_loss_log.get():.3f} | \"\n            f\"val loss {val_loss_log.get():.3f} | \"\n            f\"val acc = {val_acc:.3f}\"\n        )\n\n    return model","key":"R4Az9boJui"},{"type":"output","id":"tOIjbr09Jd8n1iRXk_Fdz","data":[],"key":"jJ1qSIiFXv"}],"key":"PE59VLqJKV"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# set up the model\nmodel = LSTM(\n    input_dim=x_train.shape[-1],\n    n_classes=len(encoder.classes_),\n    hidden_dims=128,\n    num_rnn_layers=3,\n    dropout=0.1,\n    bidirectional=True,\n    use_batchnorm=False,\n    use_layernorm=True,\n)\n\n# set up the optimizer\noptimizer = Adam(model.parameters(), lr=5e-5)","key":"iSrERI0VZs"},{"type":"output","id":"1cjm8sPViNmCmYsZ5u8Ut","data":[],"key":"jjLCtB3MIG"}],"key":"zgiuMpIyhP"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"model_path = \"./model.pth\"\nif not os.path.exists(model_path):\n    n_epochs = 2 if tutorial_mode else 50\n    # train the model for a few epochs and save when training is done\n    model = train(model, optimizer, train_dataloader, validation_dataloader, epochs=n_epochs)\n    model.save(model_path)\nelse:\n    # or load the saved model from path\n    model = LSTM(\n        input_dim=x_train.shape[-1],\n        n_classes=len(encoder.classes_),\n        hidden_dims=128,\n        num_rnn_layers=3,\n        dropout=0.1,\n        bidirectional=True,\n        use_batchnorm=False,\n        use_layernorm=True,\n    )\n    model.load(model_path)\n    model.eval()","key":"ZDB7XZjGx1"},{"type":"output","id":"aSbwwus1n1Efs1PjTbIuo","data":[],"key":"R4d1fMvXUM"}],"key":"gExLOV3dt4"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"6. Run the model on validation data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xUFCIgWxMm"}],"identifier":"id-6-run-the-model-on-validation-data","label":"6. Run the model on validation data","html_id":"id-6-run-the-model-on-validation-data","implicit":true,"key":"ItjZsNuVj1"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Now that the model is trained, let’s run it on the validation data and see how well it performs.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"teZ9ay44e5"}],"key":"OeGN9yEKyP"}],"key":"BZWCB3ubhY"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# convert validation data to the proper format for inference\nn_samples = 2000 if tutorial_mode else 10000\nval_sample_mask = np.random.choice(range(len(x_validate)), n_samples)\nval_tensor = torch.from_numpy(x_validate[val_sample_mask]).transpose(1, 2)\nlogprobas = model.forward(val_tensor).cpu().detach().numpy()","key":"fzjYFuHfmo"},{"type":"output","id":"Vq2en8O_bn0rJ-213SaTZ","data":[],"key":"Ir13gbPVM9"}],"key":"XWTyMuSHNW"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# calculate the confidence and predictions\nprobas = np.exp(logprobas)\npredictions = encoder.classes_[probas.argmax(axis=1)]","key":"Bxo1mYw8dC"},{"type":"output","id":"SGF0jxxo__iRquyRaDiQK","data":[],"key":"j38n4CaEeb"}],"key":"elWtA4l2ll"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"# Calculate Accuracy, Precision and Recall, F1-Score\ny_true = y_validate[val_sample_mask]\nlabels = sorted(set(y_true) | set(predictions))\n\naccuracy = accuracy_score(y_true, predictions)\nprecision = precision_score(y_true, predictions, average=None, labels=labels)\nrecall = recall_score(y_true, predictions, average=None, labels=labels)\nf1 = f1_score(y_true, predictions, average=None, labels=labels)","key":"IpMK2y024q"},{"type":"output","id":"vfic1K2tIBeAQ_LfXsoBR","data":[],"key":"r8JZwZn0Xi"}],"key":"Cuq0mGucUB"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Plot F1-score per label","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RXtoteHuRs"}],"key":"edgjq5hHUU"}],"key":"byyg4weqMf"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots(figsize=(12, 5))\n\n# calculate F1 score dataframe\ndf_f1 = pd.DataFrame({\"Code\": lbl, \"Label\": [labels_dict[lbl] for lbl in labels], \"F1 score\": f1})\n\n# plot scores\nax.barh(df_f1[\"Label\"], df_f1[\"F1 score\"])\n\nax.set_title(\"Labels F1-Score\")\nax.set_xlabel(\"F1-Score\")","key":"PN8gZwghxL"},{"type":"output","id":"Zl9mEzx_lsWKRo_JnoiAw","data":[],"key":"CvDd18JL6C"}],"key":"J4NgumFqye"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Plot confusion matrix","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TxmTorqNpk"}],"key":"X080ueLdre"}],"key":"j2O9gmc1UR"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"true_labels_counts_dict = dict(zip(*np.unique(y_validate[val_sample_mask].tolist(), return_counts=True)))\ncounts = [true_labels_counts_dict.get(lbl, 0) for lbl in labels]\n\nlabels = np.array(labels)[np.argsort(counts)[::-1]]\ncounts = sorted(counts)[::-1]\n\ncm = confusion_matrix(y_true, predictions, normalize=\"true\", labels=labels)\nax = sns.heatmap(\n    cm,\n    annot=True,\n    cmap=\"Greens\",\n    fmt=\".2f\",\n    xticklabels=[labels_dict[lbl] for lbl in labels],\n    yticklabels=[f\"{labels_dict[lbl]}\\n({c})\" for lbl, c in zip(labels, counts)],\n    cbar=False,\n    annot_kws={\"color\": \"black\"},\n)\nax.set_xlabel(\"Predicted labes\")\nax.set_ylabel(\"True labels\")\nax.set_title(\"Confusion matrix\")\nplt.show()","key":"qXwFG1EIHZ"},{"type":"output","id":"9KLWgWuifN9p-eR3tZqoJ","data":[],"key":"jKh8ORBpEJ"}],"key":"JwWBjhlDFt"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Plot time series according to the true label","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LS1MzA4Yi1"}],"key":"k7DoJc4KPw"}],"key":"jDLzTUtBGx"},{"type":"block","kind":"notebook-code","data":{},"children":[{"type":"code","lang":"python","executable":true,"value":"ncols = 3\nnrows = len(encoder.classes_) // ncols + 1\n\nfig, axs = plt.subplots(figsize=(15, 7), nrows=nrows, ncols=ncols)\n\nn, t, c = x_validate.shape\nplot_data = val_scaler.inverse_transform(x_validate.reshape(n * t, c)).reshape(n, t, c)[val_sample_mask]\nndvi = (plot_data[..., 3] - plot_data[..., 2]) / (plot_data[..., 3] + plot_data[..., 2])\n\nfor idx, (ax, cc) in enumerate(zip(axs.ravel(), encoder.classes_)):\n    ax.plot(ndvi[y_true == cc][:200].T, color=f\"C{idx}\", alpha=0.1)\n    ax.set_title(f\"Crop Type {cc} ({labels_dict[cc]})\")\n\nplt.tight_layout()","key":"faGkbHXqmx"},{"type":"output","id":"Z8p_jXKXzltDnJiE1bEqC","data":[],"key":"mAYytm8pFs"}],"key":"lCTHczfxMK"},{"type":"block","kind":"notebook-content","data":{},"children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Plot time series according to the predicted label","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ULMwfaCQP3"}],"key":"Nl96Uw3tqc"}],"key":"AbJ9UIkbIu"},{"type":"block","kind":"notebook-code","data":{"tags":[]},"children":[{"type":"code","lang":"python","executable":true,"value":"ncols = 3\nnrows = len(encoder.classes_) // ncols + 1\n\nfig, axs = plt.subplots(figsize=(15, 7), nrows=nrows, ncols=ncols)\n\nfor idx, (ax, cc) in enumerate(zip(axs.ravel(), encoder.classes_)):\n    ax.plot(ndvi[predictions == cc][:200].T, color=f\"C{idx}\", alpha=0.1)\n    ax.set_title(f\"Crop Type {cc} ({labels_dict[cc]})\")\n\nplt.tight_layout()","visibility":"show","key":"YeIICsKtuM"},{"type":"output","id":"GtJKi7IAL1C4AxP7PcvwG","data":[],"visibility":"show","key":"CUoAosb3EF"}],"visibility":"show","key":"rECtDYrKIy"}],"key":"TgrjEiWkxl"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Demonstration of Eurocrops data use in geoDB","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-geodb-4-eurocrops-demo","group":"Contributions"},"next":{"title":"Important notes","url":"/external-notebooks/eurodatacube/notebooks/notebooks/contributions/edc-usecase-lpis-crop-type-classification","group":"Contributions"}}},"domain":"http://localhost:3000"}